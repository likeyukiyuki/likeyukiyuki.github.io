<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yuki</title>
  
  
  <link href="http://likeyukiyuki.github.io/atom.xml" rel="self"/>
  
  <link href="http://likeyukiyuki.github.io/"/>
  <updated>2023-10-06T15:05:18.159Z</updated>
  <id>http://likeyukiyuki.github.io/</id>
  
  <author>
    <name>yuki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2023-10-06周报</title>
    <link href="http://likeyukiyuki.github.io/2023/10/06/2023-10-06%E5%91%A8%E6%8A%A5/"/>
    <id>http://likeyukiyuki.github.io/2023/10/06/2023-10-06%E5%91%A8%E6%8A%A5/</id>
    <published>2023-10-05T16:20:46.000Z</published>
    <updated>2023-10-06T15:05:18.159Z</updated>
    
    <content type="html"><![CDATA[<p>本周学习了一些关于机器学习的算法，这里将对它们做一个总结和比较：</p><h2 id="首先是线性回归算法（Linear-Regression）："><a class="header-anchor" href="#首先是线性回归算法（Linear-Regression）：">¶</a>首先是线性回归算法（Linear Regression）：</h2><p>优点：<br>1、原理较为简单，因此实现起来会比较容易，而且计算过程简单，因此建模速度很快。<br>2、十分容易理解，结果具有很好的可解释性，有利于决策分析。<br>缺点：<br>1、局限于线性数据，不适用于非线性数据<br>2、不适用于高度复杂的数据，容易欠拟合<br>3、对异常值非常敏感</p><p>适用场景：<br>因变量是连续值，并且与影响因素有线性关系时。例如我们有一个数据集，数据集里面有很多x和y。x与y存在某种线性关系，并且是y根据x的值改变，那么当我们想要预测在某个x值时，该x值对应的y值是多少时，就可以使用线性回归建模。</p><p>举例：<br>当我们有一系列房屋的面积大小x与价格y对应关系的数据时，想要预测200㎡的房间（x值）对应的价格（y值）是多少，就可以用线性回归建模。或者是我们知道某个品牌的手机价格x与销量y对应关系的数据时，想要预测某款新机的定价（x值）能有多少销量（y值）是多少，也可以使用线性回归。</p><h2 id="支持向量机SVM（support-vector-machines）"><a class="header-anchor" href="#支持向量机SVM（support-vector-machines）">¶</a>支持向量机SVM（support vector machines）</h2><p>优点：<br>1、SVM分类思想较简单，最终的决策函数是由少数支持向量决定的，因此可以在一定程度上避免特征空间的维数过大的问题。<br>2、SVM利用核函数不同可以处理分类和回归问题，线性和非线性的问题。<br>3、SVM进行二分类时效果很好<br>4、SVM可以利用核函数向高维空间映射，因此无论特征空间是高维还是低维表现都很好<br>缺点：<br>1、适用于小样本，当样本数量过大时，训练速度会非常慢<br>2、传统的SVM只能进行二分类，对于多分类效果不好<br>3、对于核函数的选择以及参数的调整需要花很大功夫，因为它们对于样本的训练效果有着很大影响。</p><p>适用场景：<br>当样本数量比较小，线性可分，参数比较少时，选择linear内核的SVM模型；线性不可分，参数比较多时，选择RBF内核的SVM模型，需要调参哦。其实根据选择的核函数不同，SVM的适用场景也有很多，如果是使用监督学习的话，样本合适的情况下，都可以尝试一下SVM。</p><p>举例：<br>比如判断一个邮件是否是垃圾邮件，如果我们拥有一些正常的邮件和垃圾邮件，就可以提取某些特征使用SVM进行建模，最后得到的模型就可以对邮件进行分类。</p><h2 id="k-means"><a class="header-anchor" href="#k-means">¶</a>k-means</h2><p>优点：<br>1、原理较简单，实现容易，收敛速度快，同时可解释度也比较强<br>2、聚类的效果很好<br>3、需要调节的参数很少，只需要调节簇数k<br>缺点：<br>1、虽然仅仅需要调节簇数k，但是k值不是可以随便选取的<br>2、使用迭代只能得到局部最优解，不一定能得到全局最优解<br>3、对于噪音和异常点比较敏感<br>4、初始聚类中心的选择有很大的影响<br>5、只能用于凸形簇</p><p>适用场景：<br>并且没有合适的标签输入，可数值化的较大数据集，由于k-means是无监督学习所以不需要输入标签，而k-means的速度很快，所以即使是大数据集也能较快的建立模型。</p><p>举例：<br>k-means可以用于新闻分类，当我们拥有大量的新闻文章时，可以使用k-means将其分为不同主题。或者通过收入、消费习惯等等，将客户分为不同的群体，以便进行更好的服务。</p><h2 id="KNN（K-Nearest-Neighbors）"><a class="header-anchor" href="#KNN（K-Nearest-Neighbors）">¶</a>KNN（K-Nearest Neighbors）</h2><p>优点：<br>1、比较适合用于多分类问题、但也可以用于回归问题<br>2、KNN是一个非参数化算法，因此适用于各种类型的数据<br>3、训练速度快，精度高<br>4、对异常值不敏感<br>缺点：<br>1、当特征数很多时，计算量很大，计算复杂度高<br>2、样本不平衡时，对于较少样本类别的预测不太准确<br>3、需要大量的存储空间</p><p>适用场景：KNN适用于较小的数据集，因为其原理计算复杂程度很高。可以用于非线性的数据集，但是不太适用于数据不平均的情况。</p><p>举例：<br>KNN的实际应用举例其实与k-means较为相似，由于都主要解决分类/聚类。而KNN是一种监督学习算法，所以需要输入标签，这是一个本质的差异。KNN也可以进行客户分类、图像分类等等。</p><h2 id="四种算法对比"><a class="header-anchor" href="#四种算法对比">¶</a>四种算法对比</h2><p>从解决问题方面来说<br>回归：线性回归、SVM、KNN<br>分类：SVM、KNN<br>聚类：k-means</p><p>接着是数据是否线性<br>线性：线性回归、SVM、KNN<br>非线性：SVM、KNN</p><p>数据集的大小<br>大数据集：线性回归<br>小数据集：SVM、KNN</p><p>以上是从三个不同方面对比，但是具体使用哪个算法进行建模，还是需要根据具体的问题进行分析后选择的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本周学习了一些关于机器学习的算法，这里将对它们做一个总结和比较：&lt;/p&gt;
&lt;h2 id=&quot;首先是线性回归算法（Linear-Regression）：&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#首先是线性回归算法（Linear-Regression）：</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>KNN算法（K Nearest Neighbors）/k近傍法</title>
    <link href="http://likeyukiyuki.github.io/2023/09/28/KNN%E7%AE%97%E6%B3%95/"/>
    <id>http://likeyukiyuki.github.io/2023/09/28/KNN%E7%AE%97%E6%B3%95/</id>
    <published>2023-09-27T17:32:02.000Z</published>
    <updated>2023-10-02T12:52:02.079Z</updated>
    
    <content type="html"><![CDATA[<h2 id="KNN算法（K-Nearest-Neighbors）-理论介绍"><a href="#KNN算法（K-Nearest-Neighbors）-理论介绍" class="headerlink" title="KNN算法（K Nearest Neighbors） 理论介绍"></a>KNN算法（K Nearest Neighbors） 理论介绍</h2><p>之前进行了k-means算法的学习，而接下来介绍的KNN算法（K Nearest Neighbors）与其有些相似，虽然都可以进行分类，但是KNN是监督学习，理论也较为简单。K Nearest Neighbors直译为K个最近的邻居，而KNN的工作原理就是输入一个特征向量x后，只选择样本数据集中与x最相似的k个数据，然后把x的类别预测为这k个样本中类别数最多的那一类。KNN算法最简单粗暴的就是将预测点与所有点距离进行计算，然后保存并排序，选出前面 K 个值看看哪些类别比较多。KNN也可以用于回归预测，同样是寻找距离最近的k个样本，然后对这k个样本的目标值去均值即可作为新样本的预测值。</p><p>&#x2F;KNNアルゴリズム（K Nearest Neighbors）は、以前に紹介したk-meansアルゴリズムと多少似ているが、どちらも分類を行うことができるが、KNNは教師あり学習であり、理論はより単純である。k Nearest NeighborsはK最近傍と訳され、KNNの原理は、特徴ベクトルxを入力した後サンプルデータセットの中からxに最も似ているk個のデータだけを選び、そのk個のサンプルの中で最もカテゴリー数が多いものをxのカテゴリーと予測する。KNNアルゴリズムの最も単純で粗雑な部分は、予測された点とすべての点の間の距離を計算し、どのカテゴリーが多いかを見るために最初のK個の値を保存して並べ替えることである。 KNNは回帰予測にも使用でき、同じように最も近いk個のサンプルを見つけ、その平均に対するk個のサンプルの目標値を新しいサンプルの予測値として使用できる。</p><h2 id="KNN-demo"><a href="#KNN-demo" class="headerlink" title="KNN demo"></a>KNN demo</h2><p>接下来通过一个分类预测的demo来解释KNN的基本原理及过程 &#x2F;次に、分類予測のデモを通して、KNNの基本原理とプロセスを説明する：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入所需要的包 /必要なパッケージをインポートする</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>导入数据和标签，划分训练集和测试集，并且利用train_test_split()函数打乱，其中参数未划分的数据集X，未划分的标签y，随机数种子random_state&#x3D;2003，应用于分割前对数据的洗牌。</p><p>&#x2F;データとラベルがインポートされ、トレーニングセットとテストセットが分割され、train_test_split()関数を用いて、セグメンテーションされていないデータセットX、セグメンテーションされていないラベルy、乱数シード（random_state&#x3D;2003）は、セグメンテーションの前にデータをシャッフルするために使用する。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入iris数据 / irisデータのインポート</span></span><br><span class="line">iris = datasets.load_iris() </span><br><span class="line">X = iris.data <span class="comment">#数据集 /データセット</span></span><br><span class="line">y = iris.target <span class="comment">#标签 /タブ</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">2003</span>)</span><br></pre></td></tr></table></figure><p>计算两个样本之间的距离 &#x2F;2つのサンプル間の距離を計算する</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">euc_dis</span>(<span class="params">instance1, instance2</span>):</span><br><span class="line">    </span><br><span class="line">    dist = np.sqrt(np.<span class="built_in">sum</span>((instance1-instance2)**<span class="number">2</span>)) <span class="comment">#对instance1和instance2求差的平方和，即利用欧式公式求距离</span></span><br><span class="line">    <span class="keyword">return</span> dist</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">knn_classify</span>(<span class="params">X, y, testInstance, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    给定一个测试数据testInstance, 通过KNN算法来预测它的标签。 /テストデータtestInstanceが与えられると、そのラベルはKNNアルゴリズムによって予測される。</span></span><br><span class="line"><span class="string">    X: 训练数据的特征 /トレーニングデータの特徴</span></span><br><span class="line"><span class="string">    y: 训练数据的标签 /トレーニングデータのラベル</span></span><br><span class="line"><span class="string">    testInstance: 测试数据，这里假定一个测试数据 array型 / テストデータ、ここではテストデータを想定 array</span></span><br><span class="line"><span class="string">    k: 选择多少个neighbors? /いくつのneighborsから選べますか？</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 testInstance 与 X的距离 /testInstanceとXの距離を計算する。</span></span><br><span class="line">    dists=[euc_dis(x,testInstance) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 找出最近的K个元素的idx /最も近いK個の要素のidxを求める</span></span><br><span class="line">    idxknn= np.argsort(dists)[:k] <span class="comment">#将dists从小到大排序，返回排序后的元素 /distsを小さいものから大きいものへとソートし、ソートされた要素を返す</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 找出KNN对应的n个y值 /KNNに対応するn個のy値を求める</span></span><br><span class="line">    yknn=y[idxknn]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回数组中出现最多次数的值 /配列中の出現回数が最も多い値を返します。</span></span><br><span class="line">    <span class="keyword">return</span> Counter(yknn).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>预测结果 &#x2F;予想される結果：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">predictions = [knn_classify(X_train, y_train, data, <span class="number">3</span>) <span class="keyword">for</span> data <span class="keyword">in</span> X_test] <span class="comment">#遍历测试集中数据，并且通过KNN得到其对应标签</span></span><br><span class="line">correct = np.count_nonzero((predictions==y_test)==<span class="literal">True</span>) <span class="comment">#将预测标签与测试集标签进行对比，得到正确的标签个数 /正しいラベル数を得るために、予測されたラベルとテストセットのラベルを比較する</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Accuracy is: %.3f&quot;</span> %(correct/<span class="built_in">len</span>(X_test))) <span class="comment">#通过len()得到测试集标签个数，相除得到准确率 /使用 len() 获取测试集中的标签数量，然后除以正确率</span></span><br></pre></td></tr></table></figure><p>KNN算法的demo讲解就到此为止啦~ &#x2F; これでKNNアルゴリズムのデモは終わりである</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;KNN算法（K-Nearest-Neighbors）-理论介绍&quot;&gt;&lt;a href=&quot;#KNN算法（K-Nearest-Neighbors）-理论介绍&quot; class=&quot;headerlink&quot; title=&quot;KNN算法（K Nearest Neighbors） 理论介</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>k-means算法 / k平均法</title>
    <link href="http://likeyukiyuki.github.io/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    <id>http://likeyukiyuki.github.io/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-09-27T10:49:47.000Z</published>
    <updated>2023-10-02T12:51:40.616Z</updated>
    
    <content type="html"><![CDATA[<h2 id="无监督学习-（Unsupervised-Learning）"><a href="#无监督学习-（Unsupervised-Learning）" class="headerlink" title="无监督学习 （Unsupervised Learning）"></a>无监督学习 （Unsupervised Learning）</h2><p>通过k-means算法的学习，算是正式步入了无监督学习的大门。那么再介绍k-means之前先介绍一下无监督学习吧~<br>首先在之前的学习中，知道了监督学习和无监督学习的区别在于有无标签的输入。而无监督学习主要方向是聚类，聚类顾名思义就是物以类聚，人以群分。</p><p>&#x2F;k-meansアルゴリズムを学ぶことで、教師なし学習の扉に正式に足を踏み入れた。 そこでk-meansを紹介する前に、教師なし学習を紹介しよう。まず、これまでの研究で、教師あり学習と教師なし学習の違いは、ラベル付き入力の有無であることが知られている。 そして、教師なし学習の主な方向性はクラスタリングであり、クラスタリングとはその名の通り、牛は牛連れ、馬は馬連れ。</p><h3 id="聚类-Clustering"><a href="#聚类-Clustering" class="headerlink" title="聚类(Clustering)"></a>聚类(Clustering)</h3><p>聚类是按照某个特定标准(如距离)把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。也即聚类后同一类的数据尽可能聚集到一起，不同类数据尽量分离。<br>这么说可能有点抽象，通俗的来说就是把相似的数据划分到一起，就像合得来的人聚在一起一样。</p><p>&#x2F;クラスタリングとは、データセットを特定の基準（距離など）に従って異なるクラスまたはクラスタに分割するプロセスであり、同じクラスタ内のデータオブジェクトは可能な限り類似しており、同時に同じクラスタに含まれないデータオブジェクトは可能な限り異なっている。 つまり、クラスタリングの結果、同じクラスのデータは可能な限り集められ、異なるクラスのデータは可能な限り分離される。<br>少し抽象的かもしれないが、一般論としては、気の似合う人が集まるように、似たようなデータを一緒に分けることである。</p><h3 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h3><p>而接下来介绍的k-means算法就能很好的划分数据集，它的工作原理是先规定好需要划分的簇类或聚类中心，就像一个班级里的人需要分成小组，那么分成几组或者以哪些人为组长是要首先确定的。接着通过反复迭代，直至达成”簇内的点足够近，簇间的点足够远”的目标。也就是说分好了组选好了组长后由于各种各样的因素影响，最开始划分的小组内组员目标不一定都是一致的，那么会出现组员换组，选举换组长之类的现象。直至最后的小组成员目标一致、关系紧密、组长无可替代，同时每个组做事风格差别极其大，这时候整个班才算被完美的分成三个完全不同的组。</p><p>&#x2F; 次に紹介するK平均法アルゴリズムは、データセットをうまく分割することができ、その動作原理は、クラスの人々をグループに分割する必要があるのと同じように、分割する必要のあるクラスターまたはクラスターセンターを最初に指定することです。 その後、繰り返しの繰り返しを経て、「クラスター内のポイントが十分に近く、クラスター間のポイントが十分に離れている」という目標が達成されるまで。 つまり、グループを分割してリーダーを選出した後、さまざまな要因により、最初に分割されたグループのメンバーの目標が同じでない場合があれば、グループを変更してリーダーを選出してなどの現象が発生します。 最終的なグループメンバーが同じ目標、緊密な関係、かけがえのないグループリーダーを持ち、各グループの仕事のスタイルが非常に異なり、その時点でクラス全体が3つの完全に異なるグループに分割されるまでではありません。<br>接下来通过demo进一步讲解k-means算法的过程。 &#x2F;k-meansアルゴリズムのプロセスは、次にデモを通してさらに説明される。</p><h2 id="k-means-demo"><a href="#k-means-demo" class="headerlink" title="k-means demo"></a>k-means demo</h2><p>经典导入所需要的包 &#x2F;必要なパッケージをインポートする：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br></pre></td></tr></table></figure><p>读取初始数据，画图展示 &#x2F;初期データを読み、図を書いて示す：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = sio.loadmat(<span class="string">&quot;data/ex7data2.mat&quot;</span>)</span><br><span class="line">X = data[<span class="string">&#x27;X&#x27;</span>]</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">ax.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>],c=<span class="string">&quot;b&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/output1.png"><br>定义函数find_closest_centroids()找到数据中每个实例最接近的聚类中心的数据，centroids是数据点初始化中心，k-means算法的一个特点是初始质心对聚类结果和运行时间有着很大影响，所以最好是手动设置（一般输入为点坐标的数组）。</p><p>&#x2F;関数 find_closest_centroids() を定義して、データ中の各インスタンスに最も近いクラスタリング中心を求めます。centroids はデータ点の初期化中心で、k-means アルゴリズムは初期セントロイドの特徴がクラスタリング結果と実行時間に大きな影響を与えるので、手動で設定するのが最善です（一般的な入力は点の座標の配列です）</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_closest_centroids</span>(<span class="params">X, centroids</span>):</span><br><span class="line">    m = X.shape[<span class="number">0</span>]<span class="comment">#读取x第一维度的长度,即数据的条数 /xの最初の次元の長さ、すなわちデータの本数を読み取る</span></span><br><span class="line">    k = centroids.shape[<span class="number">0</span>]<span class="comment">#读取点个数，即簇数 /読み取りポイントの数、つまり、クラスターの数です</span></span><br><span class="line">    idx = np.zeros(m)<span class="comment">#得到一个有m个元素的数组 /m個の要素を持つ配列を取得する</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m): </span><br><span class="line">        min_dist = <span class="number">1000000</span> <span class="comment">#设置一个很大的初始最小距离 /大きな初期最小距離を設定する</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            dist = np.<span class="built_in">sum</span>((X[i,:] - centroids[j,:]) ** <span class="number">2</span>)<span class="comment">#遍历所有数据点以及中心点求方差和，得到一个数据点与某一中心点的距离 /すべてのデータポイントと中心点を反復処理し、分散の合計を見つけて、中心点からデータポイントの距離を取得します</span></span><br><span class="line">            <span class="keyword">if</span> dist &lt; min_dist: <span class="comment">#进行比较 /比較する</span></span><br><span class="line">                min_dist = dist <span class="comment">#更新最小的距离 /最小距離の更新</span></span><br><span class="line">                idx[i] = j <span class="comment">#将该最小距离的中心点下标值赋给idx数组 /この最小距離のセントロイド添え字の値をidx配列に代入する</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> idx <span class="comment">#得到一个拥有各数据点对应的最近中心点的下标的数组 /各データ点に対応する最近傍のセントロイドの添え字を持つ配列を得る</span></span><br></pre></td></tr></table></figure><p>设置初始质心，调用函数find_closest_centroids() &#x2F;初期セントロイドを設定するには、関数 find_closest_centroids() を呼び出します：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">initial_centroids = np.array([[<span class="number">3</span>, <span class="number">3</span>], [<span class="number">6</span>, <span class="number">2</span>], [<span class="number">8</span>, <span class="number">5</span>]]) <span class="comment">#手动初始化三个聚类中心点 /3つのクラスタ・セントロイドを手動で初期化する</span></span><br><span class="line">idx = find_closest_centroids(X,initial_centroids)<span class="comment">#调用函数 /コール機能</span></span><br><span class="line"><span class="built_in">print</span>(idx[<span class="number">0</span>:<span class="number">3</span>]) <span class="comment">#打印出前三个值看看是否成功 /最初の3つの値をプリントアウトして、うまくいったかどうかを確認する</span></span><br></pre></td></tr></table></figure><p>定义函数compute_centroids()对目前靠近某个质心的数据点求均值 &#x2F;compute_centroids()関数を定義して、あるセントロイドに近いデータ点の平均を求める：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_centroids</span>(<span class="params">X, idx, k</span>):</span><br><span class="line">    m, n = X.shape</span><br><span class="line">    centroids = np.zeros((k, n)) <span class="comment">#定义一个数组存放新质心的坐标 /新しいセントロイドの座標を保存する配列を定義する</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        indices = X[np.where(idx == i)[<span class="number">0</span>]]  <span class="comment"># np.where找出在idx中与i值相等的值的下标，返回值类型是元组,[0]是取内部数据 /np.whereでidxとiの値が等しい添え字の値に見つけるために、戻り値の型はタプルであり、[0]は、内部データを取ることです</span></span><br><span class="line">        centroids[i] = np.mean(indices, <span class="number">0</span>)  <span class="comment"># 按列求均值 /列ごとに平均を求める</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> centroids <span class="comment">#返回一个含有新质心坐标的数组 /新しいセントロイドの座標を含む配列を返す</span></span><br></pre></td></tr></table></figure><p>构建k-means算法，X数据集，initial_centroids初始质心，max_iters最大迭代次数 &#x2F;k-meansアルゴリズムの構築、Xデータセット、initial_centroids初期セントロイド、max_iters最大反復数：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_k_means</span>(<span class="params">X, initial_centroids, max_iters</span>):</span><br><span class="line">    m,n = X.shape</span><br><span class="line">    k = initial_centroids.shape[<span class="number">0</span>]</span><br><span class="line">    idx = np.zeros(m)</span><br><span class="line">    centroids = initial_centroids</span><br><span class="line">    <span class="comment">#开始进行迭代 /イテレーションの開始</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_iters):</span><br><span class="line">        idx = find_closest_centroids(X,centroids) <span class="comment"># 找到最近质心 /最も近いセントロイドを見つける。</span></span><br><span class="line">        centroids = compute_centroids(X,idx,k) <span class="comment"># 重新计算质心 /セントロイドを再計算する</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> idx,centroids </span><br></pre></td></tr></table></figure><p>运行k-means后，画图展示 &#x2F; k-meansを実行した後、グラフを描く:</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">idx, centroids = run_k_means(X, initial_centroids, <span class="number">10</span>)<span class="comment">#运行k-means /k-meansを実行する</span></span><br><span class="line">cluster_1 = X[np.where(idx==<span class="number">0</span>)[<span class="number">0</span>],:]<span class="comment">#第一个簇内数据点 /最初のクラスター内データポイント</span></span><br><span class="line">cluster_2 = X[np.where(idx==<span class="number">1</span>)[<span class="number">0</span>],:]<span class="comment">#第二个簇 /第2クラスタ</span></span><br><span class="line">cluster_3 = X[np.where(idx==<span class="number">2</span>)[<span class="number">0</span>],:]<span class="comment">#第三个簇 /第3クラスタ</span></span><br><span class="line"><span class="comment">#画图 /グラフを描く</span></span><br><span class="line">fig,ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">ax.scatter(cluster_1[:,<span class="number">0</span>],cluster_1[:,<span class="number">1</span>],c=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;cluster_1&#x27;</span>)</span><br><span class="line">ax.scatter(cluster_2[:,<span class="number">0</span>],cluster_2[:,<span class="number">1</span>],c=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;cluster_2&#x27;</span>)</span><br><span class="line">ax.scatter(cluster_3[:,<span class="number">0</span>],cluster_3[:,<span class="number">1</span>],c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;cluster_3&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/output2.png"><br>以上是k-means算法的实现过程，接下来是实现应用 &#x2F;上記は、k-meansアルゴリズムの実装プロセスであり、次にアプリケーションの実装が続く：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看原始图片 /元の画像を見る</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line">Image(filename=<span class="string">&#x27;bird_small.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/bird_small.png"><br>加载图片数据，并且查看 &#x2F;画像データを読み込んで表示する：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image_data = loadmat(<span class="string">&#x27;bird_small.mat&#x27;</span>)</span><br><span class="line">image_data.keys()  <span class="comment"># 查看mat格式数据有哪些内容 /matフォーマットデータの中身を見る</span></span><br><span class="line">data = image_data[<span class="string">&#x27;A&#x27;</span>] <span class="comment">#获取数据 /データ取得</span></span><br><span class="line">data.shape            <span class="comment"># 图像为128*128 3通道的图片 /画像は128*128の3チャンネル画像</span></span><br></pre></td></tr></table></figure><p>由于各通道数据的数值差别还比较大，需要对数据应用一些预处理。 &#x2F;チャンネルデータの値はまだかなり異なるので、データに何らかの前処理を施す必要がある</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = data / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置矩阵大小，将行数和列数合并，通道为单独的一维 /マトリックスのサイズをリセット、行と列を組み合わせる、チャンネルは一次元の独立したものである</span></span><br><span class="line">X = np.reshape(data, (data.shape[<span class="number">0</span>] * data.shape[<span class="number">1</span>], data.shape[<span class="number">2</span>]))</span><br><span class="line">k = <span class="number">16</span></span><br><span class="line">max_iters = <span class="number">10</span></span><br><span class="line">X.shape</span><br></pre></td></tr></table></figure><p>进行图像压缩 &#x2F;画像圧縮の実行：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机初始化聚类中心 /クラスタ中心のランダムな初期化</span></span><br><span class="line">init_centroids = random_init_centroids(X, k)</span><br><span class="line"><span class="comment"># 获取聚类中心 /クラスタリングセンターの取得</span></span><br><span class="line">idx, centroids = run_k_means(X, init_centroids, max_iters)</span><br><span class="line"><span class="comment"># 将所有数据点归属到对应的聚类中心 /すべてのデータ点を対応するクラスタ中心に帰属させる</span></span><br><span class="line">idx = find_closest_centroids(X, centroids)</span><br><span class="line"><span class="comment"># 将每一个像素值与聚类结果进行匹配 /各ピクセル値をクラスタリング結果とマッチさせる</span></span><br><span class="line">X_recovered = centroids[idx.astype(<span class="built_in">int</span>), :]  <span class="comment"># 将属于一个聚类的像素，设置为聚类中心的值（统一） /クラスタに属するピクセルをクラスタ中心の値に設定します（一様）</span></span><br><span class="line"><span class="comment"># X_recovered.shape (16384, 3)</span></span><br><span class="line">X_recovered = np.reshape(X_recovered, (data.shape[<span class="number">0</span>], data.shape[<span class="number">1</span>], data.shape[<span class="number">2</span>])) <span class="comment"># 再展开为三维数据 /3次元データへの展開</span></span><br><span class="line">X_recovered.shape</span><br></pre></td></tr></table></figure><p>展示出压缩后的图像 \圧縮画像を表示する：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(X_recovered)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/output3.png"></p><p>可以看到刚刚我们虽然压缩了图片，但是效果不是很好，清晰度变得很差，接下来使用scikit-learn的k-means算法压缩图像。 </p><p>&#x2F;先ほど画像を圧縮しましたが、効果はあまりなく、鮮明さが非常に悪くなっていることがわかります。次に、scikit-learnのk-meansアルゴリズムを使って画像を圧縮します。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">pic = io.imread(<span class="string">&#x27;data/bird_small.png&#x27;</span>) / <span class="number">255.</span> <span class="comment"># 加载图片并进行归一化处理 /画像を読み込んで正規化する</span></span><br><span class="line">io.imshow(pic)</span><br></pre></td></tr></table></figure><p><img src="/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/output4.png"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pic.shape   <span class="comment"># 查看图像数据形状信息，即：宽、高位128、128，3通道 /画像データの形状情報（幅、高さのビット128、128、3チャンネル）を表示する。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 类似之前的操作，重置图像大小 /前の操作と同様に画像サイズをリセットする</span></span><br><span class="line">data = pic.reshape(<span class="number">128</span>*<span class="number">128</span>, <span class="number">3</span>)</span><br><span class="line">data.shape</span><br><span class="line"><span class="comment">#导入k-means库 /k-meansライブラリのインポート</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="comment"># 构建kmeans算法模型 /kmeansアルゴリズムのモデル化</span></span><br><span class="line">model = KMeans(n_clusters=<span class="number">16</span>, n_init=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 开始训练 /トレーニング開始</span></span><br><span class="line">model.fit(data)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 得到各簇中心点 /各クラスタのセントロイドを取得する</span></span><br><span class="line">centroids = model.cluster_centers_  </span><br><span class="line"><span class="built_in">print</span>(centroids.shape)              <span class="comment"># 查看簇的形状 \クラスターの形状を見る</span></span><br><span class="line">C = model.predict(data)             <span class="comment"># 获取每条数据所属簇 \各データが属するクラスタを取得する</span></span><br><span class="line">C.shape</span><br><span class="line"></span><br><span class="line">centroids[C].shape  </span><br><span class="line">compressed_pic = centroids[C].reshape((<span class="number">128</span>,<span class="number">128</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># 绘制原图和压缩图片 /オリジナル画像と圧縮画像の描画</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">ax[<span class="number">0</span>].imshow(pic)</span><br><span class="line">ax[<span class="number">1</span>].imshow(compressed_pic)</span><br></pre></td></tr></table></figure><p><img src="/2023/09/27/kmean%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/output5.png"><br>那么demo的部分也就到此为止啦~ &#x2F;これでデモは終わり。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;无监督学习-（Unsupervised-Learning）&quot;&gt;&lt;a href=&quot;#无监督学习-（Unsupervised-Learning）&quot; class=&quot;headerlink&quot; title=&quot;无监督学习 （Unsupervised Learning）&quot;&gt;&lt;/a</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>linear SVM</title>
    <link href="http://likeyukiyuki.github.io/2023/09/26/linear%20SVM/"/>
    <id>http://likeyukiyuki.github.io/2023/09/26/linear%20SVM/</id>
    <published>2023-09-25T17:02:42.000Z</published>
    <updated>2023-10-05T16:15:42.814Z</updated>
    
    <content type="html"><![CDATA[<h1>linear SVM</h1><p>支持向量机（support vector machines, SVM）是监督学习中一种二分类算法，它的原理是找到一个超平面划分两类样本。SVM不仅仅可以用于分类问题，也可以用于回归，但是通常还是用于二分类问题的。</p><p>/サポートベクターマシン(SVM)は、教師あり学習における二項分類アルゴリズムであり、2種類のサンプルを分割します超平面を見つけることによって機能します。 SVMは、分類問題だけでなく回帰にも使用できますが、二項分類問題によく使用されます。<br><img src="/2023/09/26/linear%20SVM/01.png" alt></p><h2 id="核函数（kernel-function）"><a class="header-anchor" href="#核函数（kernel-function）">¶</a>核函数（kernel function）</h2><p>SVM可以选择不同的核函数，也可以处理一些非线性的问题。常用的核函数有线性核函数、高斯核函数，一般来说，参数较少、并且线性可分时可以使用线性核函数，而参数比较多、线性不可分的时候可以使用高斯核函数。</p><p>/SVM は、異なるカーネル関数を選択したり、いくつかの非線形問題を処理したりできます。 一般的に使用されるカーネル関数は、線形カーネル関数、ガウスカーネル関数であり、一般に、線形カーネル関数は、パラメータが少なく線形に割り切れる場合に使用でき、ガウスカーネル関数は、より多くのパラメータと線形不可分性がある場合に使用できます。</p><h2 id="软间隔-ソフトマージン"><a class="header-anchor" href="#软间隔-ソフトマージン">¶</a>软间隔　ソフトマージン</h2><p>在我们划分样本时，很少能遇到完全线性的情况。<br>/サンプルを分割するとき、完全に線形な状況に遭遇することはめったにありません。<br><img src="/2023/09/26/linear%20SVM/02.png" alt><br>这时候我们就要放宽标准，允许一些在间隔带内的样本，也就是软间隔。<br>/このとき、標準を緩和し、スペーサーバンド内のいくつかのサンプルがあることを許可し、つまり、ソフトマージンです。<br><img src="/2023/09/26/linear%20SVM/03.png" alt><br>而对于错误样本的容忍程度在线性SVM模型中可以用参数C来设置，C是一个惩罚参数，当C越大时，样本对错误参数的容忍程度越低，C接近无穷大时，会变完全回线性的SVM；而当C为较小的有限值时，才会允许一些误差值存在。<br>/そして、線形SVMモデルの誤差サンプルの許容度は、パラメータCで設定することができます、Cはペナルティパラメータであり、Cが大きくなると、サンプルは誤差パラメータの許容度が小さくなります、Cが無限大に近づくと、線形SVMに完全に戻ってしまいます；Cがより小さい有限の値になると、その時だけ、いくつかの誤差値が存在することを許容します。</p><h2 id="SVM-linearSVC-demo"><a class="header-anchor" href="#SVM-linearSVC-demo">¶</a>SVM linearSVC demo</h2><p>对SVM学习后，运行了线性内核（linear kernels）的向量机demo。</p><p>/SVMについて学んだ後、線形カーネル（linear kernels）を使ったＳＶＭのデモが実行された。</p><p>导入相关需要的包/関連する必要なパッケージをインポートします：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn.svm</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h3 id="导入数据-load-data"><a class="header-anchor" href="#导入数据-load-data">¶</a>导入数据 load data</h3><p>读取文件，导入数据。利用scipy.io中的loadmat函数读入mat文件，用keys()可以获得字典中所有的键,get()函数返回指定键的值,DataFrame()创建dataframe，参数columns为列名：</p><p>/ファイルを読み込み、データをインポートします。 loadmat 関数で <a href="http://scipy.io">scipy.io</a> を使用して mat ファイルを読み込み、keys () で辞書内のすべてのキーを取得し、get () 関数で指定したキーの値を返します、DataFrame() はデータフレームを作成します、パラメータ columns にはカラム名を指定します：：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mat = sio.loadmat(<span class="string">&#x27;./data/ex6data1.mat&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(mat.keys())</span><br><span class="line"></span><br><span class="line">data = pd.DataFrame(mat.get(<span class="string">&#x27;X&#x27;</span>), columns=[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X2&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;y&#x27;</span>] = mat.get(<span class="string">&#x27;y&#x27;</span>)<span class="comment">#添加一列y /y列を追加</span></span><br><span class="line">data.head()<span class="comment">#打印出来前五行看看效果 /最初の5行をプリントアウトして効果を見ます</span></span><br></pre></td></tr></table></figure><p><img src="/2023/09/26/linear%20SVM/dataframe1.png" alt></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">min</span>(data[<span class="string">&#x27;X1&#x27;</span>]), <span class="built_in">max</span>(data[<span class="string">&#x27;X1&#x27;</span>]), <span class="built_in">min</span>(data[<span class="string">&#x27;X2&#x27;</span>]), <span class="built_in">max</span>(data[<span class="string">&#x27;X2&#x27;</span>]) <span class="comment">#获取data中x1的最大值和最小值，x2的最大值和最小值 /データ中のx1の最大値と最小値、およびデータ中のx2の最大値と最小値を取得します。</span></span><br></pre></td></tr></table></figure><h2 id="可视化数据-visualize-data"><a class="header-anchor" href="#可视化数据-visualize-data">¶</a>可视化数据 visualize data</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">positive = data[data.y == <span class="number">1</span>]<span class="comment">#获取一个y列都为1的dataframe /y列がすべて1のデータフレームを取得します。</span></span><br><span class="line">negative = data[data.y == <span class="number">0</span>]<span class="comment">#获取一个y列都为0的dataframe /y列がすべて0のデータフレームを取得します。</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>)) <span class="comment">#画图，siez为（width=8，height=6） /ドローイング、シーズは（width=8, height=6）</span></span><br><span class="line">ax.scatter(positive[<span class="string">&#x27;X1&#x27;</span>], positive[<span class="string">&#x27;X2&#x27;</span>], label=<span class="string">&#x27;positive&#x27;</span>, s=<span class="number">50</span>, marker=<span class="string">&#x27;+&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>)<span class="comment">#画子图，横纵坐标为positive的x1、x2，标签为positive，散点图中点大小为50，标记为&#x27;+&#x27;,颜色为红色。 /x1,x2を正の水平座標と垂直座標とし、ラベルはpositive、点サイズ50の散布図、&#x27;+&#x27;のラベル、赤色で描画します。</span></span><br><span class="line">ax.scatter(negative[<span class="string">&#x27;X1&#x27;</span>], negative[<span class="string">&#x27;X2&#x27;</span>], label=<span class="string">&#x27;negative&#x27;</span>, s=<span class="number">50</span>, marker=<span class="string">&#x27;o&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>)<span class="comment">#同上 /同上</span></span><br><span class="line">ax.legend(loc=<span class="string">&#x27;best&#x27;</span>)<span class="comment">#图例的位置为右上角 /凡例は右上隅に配置されます</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X1&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;X2&#x27;</span>)<span class="comment">#横纵坐标标签为x1,x2 /x1,x2とラベル付けされた水平および垂直座標</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="try-c-1"><a class="header-anchor" href="#try-c-1">¶</a>try c=1</h2><p>因为我们需要选择一个线性分类模型，所以选择模型sklearn库内的linearSVC模型。linear代表线性，SVC代表分类模型。sklearn库内的svm模型还有很多，例如SVR是回归模型。<br>参数C为惩罚参数，loss表示损失函数，max_iter指定最大的迭代次数。</p><p>/線形分類モデルを選択する必要があるため、モデル sklearn ライブラリ内でlinearSVC モデルを選択します。 線形は線形を表し、SVCは分類モデルを表します。 sklearnライブラリにはさらに多くのSVMモデルがあり、たとえば、SVRは回帰モデルです。<br>パラメーター C はペナルティ パラメーター 、lossは損失関数を表し、max_iterは最大反復回数を指定します。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">svc1 = sklearn.svm.LinearSVC(C=<span class="number">1</span>, loss=<span class="string">&#x27;hinge&#x27;</span>, max_iter=<span class="number">20000</span>)</span><br><span class="line">svc1.fit(data[[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X2&#x27;</span>]], data[<span class="string">&#x27;y&#x27;</span>])<span class="comment">#对数据进行训练 /データのトレーニング</span></span><br><span class="line">svc1.score(data[[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X2&#x27;</span>]], data[<span class="string">&#x27;y&#x27;</span>])<span class="comment">#利用score()函数进行评估 /score()関数による評価</span></span><br></pre></td></tr></table></figure><h3 id="决策边界-decision-boundary"><a class="header-anchor" href="#决策边界-decision-boundary">¶</a>决策边界 decision boundary</h3><p>numpy库内的arange()函数用于生成数组，参数：(起始位置，终止位置，步长)。meshgrid(x,y) :基于向量x和y中包含的坐标返回二维网格坐标。</p><p>/numpy ライブラリで、配列を生成するための range () 関数、パラメータ: (開始位置、終了位置、ステップサイズ)。meshgrid(x,y): ベクトル x と y に含まれる座標に基づいて 2 次元グリッド座標を返します。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">positive = data[data.y == <span class="number">1</span>]</span><br><span class="line">negative = data[data.y == <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">ax.scatter(positive[<span class="string">&#x27;X1&#x27;</span>], positive[<span class="string">&#x27;X2&#x27;</span>], label=<span class="string">&#x27;positive&#x27;</span>, s=<span class="number">50</span>, marker=<span class="string">&#x27;+&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax.scatter(negative[<span class="string">&#x27;X1&#x27;</span>], negative[<span class="string">&#x27;X2&#x27;</span>], label=<span class="string">&#x27;negative&#x27;</span>, s=<span class="number">50</span>, marker=<span class="string">&#x27;o&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X1&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;X2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策边界, 使用等高线表示 /等高線で表された決定境界線</span></span><br><span class="line">x1 = np.arange(<span class="number">0</span>, <span class="number">4.5</span>, <span class="number">0.01</span>)</span><br><span class="line">x2 = np.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.01</span>)</span><br><span class="line">x1, x2 = np.meshgrid(x1, x2)</span><br><span class="line">y_pred = np.array([svc1.predict(np.vstack((a, b)).T) <span class="keyword">for</span> (a, b) <span class="keyword">in</span> <span class="built_in">zip</span>(x1, x2)]) <span class="comment">#将x1、x2的值打包合并返回一个数组 进行预测（predict）/x1, x2 の値を詰め合わせて配列を返す、予測を行う。</span></span><br><span class="line">plt.contour(x1, x2, y_pred, colors=<span class="string">&#x27;g&#x27;</span>, linewidths=<span class="number">.5</span>)<span class="comment">#绘等高线 /等高線を描く</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/26/linear%20SVM/output1.png" alt></p><h3 id="直观显示样本到超平面的符号距离的不同。-サンプルから超平面までのシンボル距離の差を視覚化します。"><a class="header-anchor" href="#直观显示样本到超平面的符号距离的不同。-サンプルから超平面までのシンボル距離の差を視覚化します。">¶</a>直观显示样本到超平面的符号距离的不同。 /サンプルから超平面までのシンボル距離の差を視覚化します。</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;SVM1 Confidence&#x27;</span>] = svc1.decision_function(data[[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X2&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">ax.scatter(data[<span class="string">&#x27;X1&#x27;</span>], data[<span class="string">&#x27;X2&#x27;</span>], s=<span class="number">50</span>, c=data[<span class="string">&#x27;SVM1 Confidence&#x27;</span>], cmap=<span class="string">&#x27;seismic&#x27;</span>)<span class="comment">#颜色随着距离的变化而不同 /色は距離によって異なります</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;SVM(C=1) Decision Confidence&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X1&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;X2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策边界, 使用等高线表示 /等高線で表された決定境界線です</span></span><br><span class="line">x1 = np.arange(<span class="number">0</span>, <span class="number">4.5</span>, <span class="number">0.01</span>)</span><br><span class="line">x2 = np.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.01</span>)</span><br><span class="line">x1, x2 = np.meshgrid(x1, x2)</span><br><span class="line">y_pred = np.array([svc1.predict(np.vstack((a, b)).T) <span class="keyword">for</span> (a, b) <span class="keyword">in</span> <span class="built_in">zip</span>(x1, x2)])</span><br><span class="line">plt.contour(x1, x2, y_pred, colors=<span class="string">&#x27;g&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/26/linear%20SVM/output2.png" alt></p><h2 id="try-C-400"><a class="header-anchor" href="#try-C-400">¶</a>try C=400</h2><p>前面说过，C越大时对间隔带内存在样本的容忍度越低，所以C越大越容易过拟合，图像中最左侧的点被划分到右侧。 /前述のように、Cが大きいほどスペーサーバンド内のサンプルの許容誤差が低くなるため、Cが大きいほどオーバーフィットしやすくなり、画像の左端のポイントが右に分割されます。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">svc400 = sklearn.svm.LinearSVC(C=<span class="number">400</span>, loss=<span class="string">&#x27;hinge&#x27;</span>, max_iter=<span class="number">80000</span>)</span><br><span class="line">svc400.fit(data[[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X2&#x27;</span>]], data[<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line">svc400.score(data[[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X2&#x27;</span>]], data[<span class="string">&#x27;y&#x27;</span>])</span><br></pre></td></tr></table></figure><h3 id="C-400-决策边界-decision-boundary"><a class="header-anchor" href="#C-400-决策边界-decision-boundary">¶</a>C=400 决策边界 decision boundary</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">positive = data[data.y == <span class="number">1</span>]</span><br><span class="line">negative = data[data.y == <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">ax.scatter(positive[<span class="string">&#x27;X1&#x27;</span>], positive[<span class="string">&#x27;X2&#x27;</span>], label=<span class="string">&#x27;positive&#x27;</span>, s=<span class="number">50</span>, marker=<span class="string">&#x27;+&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax.scatter(negative[<span class="string">&#x27;X1&#x27;</span>], negative[<span class="string">&#x27;X2&#x27;</span>], label=<span class="string">&#x27;negative&#x27;</span>, s=<span class="number">50</span>, marker=<span class="string">&#x27;o&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X1&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;X2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策边界, 使用等高线表示 /等高線で表された決定境界線</span></span><br><span class="line">x1 = np.arange(<span class="number">0</span>, <span class="number">4.5</span>, <span class="number">0.01</span>)</span><br><span class="line">x2 = np.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.01</span>)</span><br><span class="line">x1, x2 = np.meshgrid(x1, x2)</span><br><span class="line">y_pred = np.array([svc400.predict(np.vstack((a, b)).T) <span class="keyword">for</span> (a, b) <span class="keyword">in</span> <span class="built_in">zip</span>(x1, x2)])</span><br><span class="line">plt.contour(x1, x2, y_pred, colors=<span class="string">&#x27;g&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/26/linear%20SVM/output3.png" alt></p><h3 id="C-400-直观显示样本到超平面的符号距离的不同。-サンプルから超平面までのシンボル距離の差を視覚化すます。"><a class="header-anchor" href="#C-400-直观显示样本到超平面的符号距离的不同。-サンプルから超平面までのシンボル距離の差を視覚化すます。">¶</a>C=400 直观显示样本到超平面的符号距离的不同。 /サンプルから超平面までのシンボル距離の差を視覚化すます。</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;SVM400 Confidence&#x27;</span>] = svc400.decision_function(data[[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X2&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">ax.scatter(data[<span class="string">&#x27;X1&#x27;</span>], data[<span class="string">&#x27;X2&#x27;</span>], s=<span class="number">50</span>, c=data[<span class="string">&#x27;SVM400 Confidence&#x27;</span>], cmap=<span class="string">&#x27;seismic&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;SVM(C=400) Decision Confidence&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X1&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;X2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策边界, 使用等高线表示  /等高線で表された決定境界線</span></span><br><span class="line">x1 = np.arange(<span class="number">0</span>, <span class="number">4.5</span>, <span class="number">0.01</span>)</span><br><span class="line">x2 = np.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.01</span>)</span><br><span class="line">x1, x2 = np.meshgrid(x1, x2)</span><br><span class="line">y_pred = np.array([svc400.predict(np.vstack((a, b)).T) <span class="keyword">for</span> (a, b) <span class="keyword">in</span> <span class="built_in">zip</span>(x1, x2)])</span><br><span class="line">plt.contour(x1, x2, y_pred, colors=<span class="string">&#x27;g&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br></pre></td></tr></table></figure><p><img src="/2023/09/26/linear%20SVM/output4.png" alt><br>打印最终的dataframe查看数据，进行对比。 /最終dataframeを印刷して、比較のためのデータを表示すます。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.head()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/26/linear%20SVM/dataframe2.png" alt><br>关于线性内核的SVM向量机demo运行学习就到此为止啦。/線形カーネルで動作しますSVMベクトルマシンのデモの研究はこれで終わりです。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;linear SVM&lt;/h1&gt;
&lt;p&gt;支持向量机（support vector machines, SVM）是监督学习中一种二分类算法，它的原理是找到一个超平面划分两类样本。SVM不仅仅可以用于分类问题，也可以用于回归，但是通常还是用于二分类问题的。&lt;/p&gt;
&lt;p&gt;/サポ</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>2023-09-24 周报/週報</title>
    <link href="http://likeyukiyuki.github.io/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/"/>
    <id>http://likeyukiyuki.github.io/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/</id>
    <published>2023-09-24T08:23:29.000Z</published>
    <updated>2023-09-25T19:29:44.891Z</updated>
    
    <content type="html"><![CDATA[<p>本周由于前四天时间都花费在往返学校以及考试中，所以学习的内容比较少，这周是关于线性回归的梯度下降算法的学习。</p><p>&#x2F;今週は、最初の4日間が学校への往復と試験を受けていたため、勉強量は少なかった。今週は、線形回帰の勾配降下アルゴリズムについてだった。</p><h1 id="理论部分-线性回归-Linear-Regression-理論的な部分-線形回帰-Linear-Regression"><a href="#理论部分-线性回归-Linear-Regression-理論的な部分-線形回帰-Linear-Regression" class="headerlink" title="理论部分 线性回归(Linear Regression) &#x2F; 理論的な部分 線形回帰 (Linear Regression)"></a>理论部分 线性回归(Linear Regression) &#x2F; 理論的な部分 線形回帰 (Linear Regression)</h1><p>线性回归是一个监督学习的算法，基于上周学习的基础可以知道，回归问题是需要得到一个具体的预测值的，而线性回归顾名思义，其函数图像是一个线性图像。训练集中有着大量数据以及其映射关系，而机器学习的目的就是得到这种映射关系。这么说起来感觉很抽象，就像一个普通的二元一次方程，当我们知道一个x和方程式那必然可以得到一个y，机器学习就是已知有许多个x与y，需要找到方程式（也就是映射关系）。用专业点的话来说就是建立了一个模型。</p><p>&#x2F; 線形回帰は、教師あり学習アルゴリズムであり、先週の学習に基づいて、回帰の問題は、線形問題は具体的な予測値を得ることになることが知られていることができ、線形回帰の名前が示すように、その関数のイメージは、線形画像です。学習セットには大量のデータとその対応関係があり、機械学習の目的はこの対応関係を得ることである。そう言うのは抽象的な感じがする、普通の2次方程式のように、xと方程式がわかれば必然的にyが求まる。機械学習とは、多くのxとyが存在し、その方程式（別名マッピング関係）を見つける必要があることを意味する。専門的な言い方をすれば、モデルは作られる。</p><h2 id="代价函数-Cost-Funcation-コスト関数-Cost-Funcation"><a href="#代价函数-Cost-Funcation-コスト関数-Cost-Funcation" class="headerlink" title="代价函数 (Cost Funcation) &#x2F; コスト関数 (Cost Funcation)"></a>代价函数 (Cost Funcation) &#x2F; コスト関数 (Cost Funcation)</h2><p>如何评价一个模型的好坏呢？这就需要引出接下来的代价函数了。当我们已经找到一个方程式，这时候我们可以对已经找到的方程输入一个x值而得到的一个y值（预测值），而同时我们又知道原本的y值（真实值），而真实值与预测值之间的差值（残差）就可以评估这个模型的好坏。但是问题是仅仅一个参数肯定没有代表性，那么我们需要对所有的进行计算然后求平方（为了消除负值）最后相加，我们就得到了预测值与真实值的方差（即代价函数cost function）用以评估模型。而我们此时的目的就转化成了找到cost function的最小值。</p><p>&#x2F; モデルの良さをどう評価するか？ これが次のコスト関数につながる。 方程式が見つかったとき、方程式にx値を入力してy値（予測値）を得ることができ、同時に元のy値（真値）を知ることができ、真値と予測値の差（残差）を使ってモデルの良し悪しを評価することができる。 しかし問題は、1つのパラメータだけでは代表性がないことです。そのため、すべてのパラメータを計算し、（負の値を排除するために）それらを2乗し、最後にそれらを合計して、予測値と真の値の分散（コスト関数 cost function）を求め、モデルを評価する必要があります。 この時点での我々の目標は、cost functionの最小値を見つけることです。<br>公式如图所示 &#x2F; 計算式を図に示す：<br><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/cost%20function.png"><br>当模型仅有一个参数时，函数的图像如图所示 &#x2F; モデルのパラメータが1つだけの場合、関数のイメージは図に示すようになる：<br><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/%E4%B8%80%E7%BB%B4%E7%BA%BF%E6%80%A7.png"><br>当模型有两个参数时，函数图像如下 &#x2F; モデルが2つのパラメータを持つ場合、関数イメージは次のようになる：<br><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/%E4%BA%8C%E7%BB%B4%E7%BA%BF%E6%80%A7.png"></p><h2 id="梯度下降法（Gradient-Descent）-勾配降下法（Gradient-Descent）"><a href="#梯度下降法（Gradient-Descent）-勾配降下法（Gradient-Descent）" class="headerlink" title="梯度下降法（Gradient Descent） &#x2F; 勾配降下法（Gradient Descent）"></a>梯度下降法（Gradient Descent） &#x2F; 勾配降下法（Gradient Descent）</h2><p>上面说到我们现在的目的是找到cost function的最小值，那么有什么方法可以准确快速的找到一个函数的最小值呢？没错，就是梯度下降法。它的工作原理是从初始点开始，不断寻找一个最优方向进行下降，直至收敛至局部最低点。而方向即是导数的方向。<br>&#x2F; 今の目標は、コスト関数の最小値を見つけることだ、では、関数の最小値を正確かつ迅速に求める最良の方法は何か？ そう、勾配降下法だ。 勾配降下法とは、初期点から最適な降下方向を常に探しながら、局所最小値に収束するまで働き続ける方法である。 その方向とは微分の方向である。<br>如图所示 &#x2F; ご覧の通りだ：<br><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.png"><br>如果初始位置不同找到的最低点也有可能不同。&#x2F;初期位置が異なれば、見つかる最低点は異なるかもしれない。<br><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.png"><br>而如果当初始点就是在局部最低点的时候，将不会继续下降了。&#x2F;また、最初のスタート地点が局所的な最小値であれば、下がり続けることはない。<br>梯度下降法的公式如图所示 &#x2F;勾配降下法の計算式を図に示す：<br><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%85%AC%E5%BC%8F.png"><br>“:&#x3D;”此符号的意思是赋值，意味着梯度下降是一个不断迭代的过程。<br>其中的”α”是决定下降的速率：α过小时，学习速率很低；α过大时，容易找不到局部最低点。<br>&#x2F; 記号”:&#x3D;”は代入を意味し、勾配降下が反復プロセスであることを意味する。<br>α “は降下率を決定する。αが小さすぎると学習率が非常に低くなり、大きすぎるとローカル・ミニマムを見つけられなくなる。</p><h2 id="线性回归的梯度下降法-線形回帰の勾配降下法"><a href="#线性回归的梯度下降法-線形回帰の勾配降下法" class="headerlink" title="线性回归的梯度下降法 &#x2F; 線形回帰の勾配降下法"></a>线性回归的梯度下降法 &#x2F; 線形回帰の勾配降下法</h2><p>最巧妙的地方就是在这里，前面说到了梯度下降法有一个问题在于它只能找到局部最优解而不是全局最优解，但是线性回归中代价函数的图像是一个凸函数，即只有一个最优解。那么在线性回归中运用梯度下降法简直是天作之合。</p><p>&#x2F; 勾配降下法には大域的な最適解ではなく局所的な最適解しか見つけられないという問題があるが、コスト関数の画像における線形回帰は凸関数であるため、最適解は1つしかない。 線形回帰における勾配降下法の使用は、まさに相性が良いのである。</p><p>那么关于线性回归的梯度下降算法的理论部分就到这里为止啦~<br>&#x2F;線形回帰の勾配降下アルゴリズムの理論的な部分はこれで終わりです。</p><h1 id="实验-线性回归算法相关demo的运行-実験-線形回帰アルゴリズムに関するdemoの実行"><a href="#实验-线性回归算法相关demo的运行-実験-線形回帰アルゴリズムに関するdemoの実行" class="headerlink" title="实验 线性回归算法相关demo的运行 &#x2F; 実験 線形回帰アルゴリズムに関するdemoの実行"></a>实验 线性回归算法相关demo的运行 &#x2F; 実験 線形回帰アルゴリズムに関するdemoの実行</h1><p>首先就是导入相关包，一般demo的开头代码如下 &#x2F; まず最初に、関連するパッケージをインポートする。典型的なdemoの冒頭のコードは以下の通りである：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><p>如果没有安装相关包在终端使用<code>pip install [包名]</code>即可，例如我需要安装numpy，则使用<code>pip install numpy</code>。以此类推，将我们需要的包安装好。</p><p>&#x2F; 関連パッケージがインストールされていない場合は、ターミナルで <code>pip install [パッケージ名]</code> を使用する。例えば、numpyをインストールする必要がある場合は、<code>pip install numpy</code> を使用する。 というように、必要なパッケージをインストールしていく。</p><p>接下来就是读取数据，我们可以直接调用pandas库内的read_csv()函数来读取，其中参数path为文件路径，header与names都可以充当列名，当names没被赋值时，header会变成0，即选取数据文件的第一行作为列名；当 names 被赋值，header 没被赋值时，那么header会变成None。如果都赋值，就会实现两个参数的组合功能。head()方法默认输出数据的前5项，这里用来查看文件是否导入成功：</p><p>&#x2F;次のステップは、データを読み込むことである。読み込みには、read_csv（）関数内でpandasライブラリを直接呼び出すことができる、pathはファイルパス。headerとnamesの両方を列名として使用することができる。 namesを割り当てない場合、headerは0になり、つまりデータファイルの最初の行が列名として選択される；namesが代入され、headerが代入されていない場合、headerはNoneになり、両方が代入されている場合、2つのパラメータの組み合わせが実現される。head()メソッドは、データの最初の5項目を出力するのがデフォルトであり、これはファイルが正常にインポートされたかどうかをチェックするために使用される：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">&#x27;ex1data1.txt&#x27;</span> <span class="comment">#路径 / path</span></span><br><span class="line">data = pd.read_csv(path, header=<span class="literal">None</span>, names=[<span class="string">&#x27;Population&#x27;</span>, <span class="string">&#x27;Profit&#x27;</span>]) <span class="comment">#读取数据的方法 / データ読み取り方法</span></span><br><span class="line">data.head() </span><br></pre></td></tr></table></figure><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/demo-head1.png" width="200"><p>然后是画图，plot()显而易见的是一种绘图函数，参数<code>kind=&#39;scatter&#39;</code>图像类型为散点图，<code>x=&#39;Population&#39;, y=&#39;Profit&#39;</code>定义x轴为’Population’、y轴为’Profit’，<code>figsize=(12,8)</code>图片尺寸大小(width&#x3D;12,height&#x3D;8)</p><p>&#x2F; それからドローイングだ。plot() は明らかにプロット関数で、パラメータ <code>kind=&#39;scatter&#39;</code> 画像タイプは散布図、<code>x=&#39;Population&#39;, y=&#39;Profit&#39;</code> は x 軸を ‘Population’, y 軸を ‘Profit’ と定義し、<code>fitsize=(12,8)</code> 画像サイズ (width&#x3D;12,height&#x3D;8) を指定します</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.plot(kind=<span class="string">&#x27;scatter&#x27;</span>, x=<span class="string">&#x27;Population&#x27;</span>, y=<span class="string">&#x27;Profit&#x27;</span>, figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/figure1.png"><br>再往dataframe添加一列数据，使用函数insert()，其中参数’0’代表添加至第一列，’Ones’代表列名为’Ones’，’1’代表插入数字’1’</p><p>&#x2F; dataframeに別の列のデータを追加する、nsert()関数を使用する。パラメータ’0’は最初のカラムへの追加を表し、’Ones’はカラム名’Ones’を表し、’1’は数値’1’の挿入を表す。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.insert(<span class="number">0</span>, <span class="string">&#x27;Ones&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/demo-head2.png" width="200"><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cols = data.shape[<span class="number">1</span>] <span class="comment">#获取列数 /列数の取得</span></span><br><span class="line">X = data.iloc[:, <span class="number">0</span>:cols-<span class="number">1</span>] <span class="comment">#得到dataframe中所有行，1列到cols-1列的数据，即第一列至第二列的数据 /dataframe内の全行、1列目からcols-1まで、つまりデータの1列目から2列目までを取得する。</span></span><br><span class="line">Y = data.iloc[:, cols-<span class="number">1</span>:cols]<span class="comment">#得到dataframe中所有行，cols-1列到cols列的数据，即第二列至第三列的数据 /dataframe内のすべての行、cols-1 から cols、つまりデータの2列目から3列目を取得する</span></span><br><span class="line">X = np.matrix(X.values) </span><br><span class="line">Y = np.matrix(Y.values)<span class="comment">#转化为矩阵 /行列への変換</span></span><br><span class="line">theta = np.matrix(np.array([<span class="number">0</span>, <span class="number">0</span>])) <span class="comment">#theta为[0,0]的矩阵 /thetaは[0,0]の行列である</span></span><br></pre></td></tr></table></figure><p>导入包，选择LinearRegression模型，使用fit()函数利用选好的模型训练数据，参数中X代表输入，Y代表输出。</p><p>&#x2F;パッケージをインポートし、LinearRegressionモデルを選択し、fit()関数を使用して、選択したモデルを使用してデータを訓練する。Xは入力、Yは出力を表す。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">model = linear_model.LinearRegression()</span><br><span class="line">model.fit(np.array(X), np.array(Y))</span><br></pre></td></tr></table></figure><p>开始绘制图像：<br>&#x2F; 画像を描き始める：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = np.array(X[:, <span class="number">1</span>].A1) <span class="comment">#得到所有x的值的数组 /すべてのx値の配列を取得する</span></span><br><span class="line">y = model.predict(np.array(X)).flatten() <span class="comment">#得到预测值y，并且降维成一维数组 /予測値yを取得して一次元配列に次元削減</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">8</span>)) <span class="comment">#画图、定义子图大小 /ダイアグラムの描画、サブダイアグラムのサイズの定義</span></span><br><span class="line">ax.plot(x, y, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;Prediction&#x27;</span>)<span class="comment">#在活跃区域绘图，坐标xy，颜色&#x27;r&#x27;即红色，标签label为&#x27;Prediction&#x27; /アクティブエリアにプロット、座標はxy、色は&#x27;r&#x27;すなわち赤、ラベルは&#x27;Prediction&#x27;。</span></span><br><span class="line">ax.scatter(data.Population, data.Profit, label=<span class="string">&#x27;Traning Data&#x27;</span>)<span class="comment">#x轴数据为data.Population，y轴数据为data.Profit，标签label为&#x27;Traning Data&#x27; /x軸のデータはdata.Population、y軸のデータはdata.Profit、ラベルのラベルは&#x27;Traning Data&#x27;である。</span></span><br><span class="line">ax.legend(loc=<span class="number">2</span>)<span class="comment">#图例位置为左上角 /レジェンドの位置は左上</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Population&#x27;</span>)<span class="comment">#x轴标签为&#x27;Population&#x27; /X軸のラベルは&#x27;Population&#x27;</span></span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Profit&#x27;</span>)<span class="comment">#y轴标签为&#x27;Profit&#x27; /Y軸のラベルは&#x27;Profit&#x27;</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Predicted Profit vs. Population Size&#x27;</span>) <span class="comment">#图片title /画像タイトル</span></span><br><span class="line">plt.show()<span class="comment">#展示图片 /写真を見る</span></span><br></pre></td></tr></table></figure><p><img src="/2023/09/24/2023-09-24%E5%91%A8%E6%8A%A5/output.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本周由于前四天时间都花费在往返学校以及考试中，所以学习的内容比较少，这周是关于线性回归的梯度下降算法的学习。&lt;/p&gt;
&lt;p&gt;&amp;#x2F;今週は、最初の4日間が学校への往復と試験を受けていたため、勉強量は少なかった。今週は、線形回帰の勾配降下アルゴリズムについてだった。&lt;/p</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>2023-09-13周报/週報</title>
    <link href="http://likeyukiyuki.github.io/2023/09/13/2023-09-13%E5%91%A8%E6%8A%A5/"/>
    <id>http://likeyukiyuki.github.io/2023/09/13/2023-09-13%E5%91%A8%E6%8A%A5/</id>
    <published>2023-09-12T17:20:35.000Z</published>
    <updated>2023-09-21T14:45:33.187Z</updated>
    
    <content type="html"><![CDATA[<p>本周将学习基础的机器学习。</p><p>&#x2F; 今週は機械学習の基本を学びます。</p><h2 id="首先是机器学习-1つ目は機械学習です"><a href="#首先是机器学习-1つ目は機械学習です" class="headerlink" title="首先是机器学习 &#x2F; 1つ目は機械学習です"></a>首先是机器学习 &#x2F; 1つ目は機械学習です</h2><p>其实在上学期我已经进行了机器学习的一个简单学习，但是掌握的不是很好，知道一些名词概念但是整体框架完全不了解。机器学习的过程是什么样的？机器学习中的某个名词起到的是什么作用？统统不了解。在这周的学习中成功的把之前所学的概念连接起来了。</p><p>&#x2F; 実際、私は前学期に機械学習の簡単な学習を行いましたが、あまりうまく習得していません。私はいくつかの名詞の概念を知っていますが、全体的な枠組みをまったく理解していません。機械学習のプロセスはどのように見えますか? 機械学習における用語はどのような役割を果たしますか? 私はそれをすべて理解しているわけではありません。 今週の学習では、以前に学んだ概念をうまく結び付けることができました。</p><h3 id="机器学习的过程-機械学習のプロセス"><a href="#机器学习的过程-機械学習のプロセス" class="headerlink" title="机器学习的过程 &#x2F; 機械学習のプロセス"></a>机器学习的过程 &#x2F; 機械学習のプロセス</h3><p>通过训练集，不断识别特征，不断建模，最后形成有效的模型，这个过程就叫做“机器学习”。</p><p>&#x2F; トレーニングセットを通じて、常に特徴を特定し、モデリングを続け、最終的に効果的なモデルを形成するこのプロセスは、「機械学習」と呼ばれます。</p><h4 id="监督学习与无监督学习-教師あり学習と教師なし学習"><a href="#监督学习与无监督学习-教師あり学習と教師なし学習" class="headerlink" title="监督学习与无监督学习 &#x2F; 教師あり学習と教師なし学習"></a>监督学习与无监督学习 &#x2F; 教師あり学習と教師なし学習</h4><p>机器学习又分为监督学习和无监督学习，监督学习是需要我们自己输入标签的，而无监督学习则不需要。由于目前只学习了监督学习，所以接下来描述的内容基本上都是监督学习相关的。</p><p>&#x2F; 機械学習は教師あり学習と教師なし学習に分けられ、教師あり学習では自分でラベルを入力する必要がありますが、教師なし学習はそうではありません。 これまでは教師あり学習しか学習していなかったため、次に説明する内容は基本的に教師あり学習です。</p><p>没有免费午餐定理 &#x2F; フリーランチ定理はありません<br>在机器学习中，有个定理被称为「没有免费的午餐」。简而言之，就是说没有一个算法可以完美解决所有问题，而且这对于监督学习（即对预测的建模）而言尤其如此。</p><p>&#x2F; 機械学習には「フリーランチがない」という定理があります。 要するに、単一のアルゴリズムがすべての問題を完全に解決できるわけではなく、これは教師あり学習、つまりモデリング予測に特に当てはまります。</p><h4 id="机器学习中的三大方向：分类、回归和聚类。-機械学習には、分類、回帰、クラスタリングという-3-つの主要な方向性があります。"><a href="#机器学习中的三大方向：分类、回归和聚类。-機械学習には、分類、回帰、クラスタリングという-3-つの主要な方向性があります。" class="headerlink" title="机器学习中的三大方向：分类、回归和聚类。 &#x2F; 機械学習には、分類、回帰、クラスタリングという 3 つの主要な方向性があります。"></a>机器学习中的三大方向：分类、回归和聚类。 &#x2F; 機械学習には、分類、回帰、クラスタリングという 3 つの主要な方向性があります。</h4><p>回归方法：是一种对数值型连续随机变量进行预测和建模的监督学习算法。简单来说就是预测的结果是数值。</p><p>&#x2F; 回帰法:数値連続確率変数を予測してモデル化する教師あり学習アルゴリズムです。 簡単に言えば、予測結果は数値です</p><p>常用算法：<br>线性回归（正则化）、回归树（集成方法）、深度学习、最近邻算法等等</p><p>&#x2F; 一般的に使用されるアルゴリズム:<br>線形回帰 (正則化)、回帰木 (アンサンブル法)、ディープ ラーニング、最近傍アルゴリズムなど</p><p>分类方法：是一种对离散型随机变量建模或预测的监督学习算法。简单来说就是预测的结果是类别。</p><p>&#x2F; 分類法:離散確率変数をモデル化または予測する教師あり学習アルゴリズムです。 簡単に言えば、予測される結果はカテゴリです。</p><p>常用算法：<br>Logistic 回归（正则化）、分类树（集成方法）、深度学习、支持向量机（SVM）、朴素贝叶斯等等。</p><p>&#x2F; 一般的なアルゴリズム:<br>ロジスティック回帰(正則化)、分類木(アンサンブル法)、深層学習、サポートベクターマシン(SVM)、ナイーブベイズなど。</p><p>聚类是一种无监督学习，所以就不介绍了。</p><p>&#x2F; クラスタリングは教師なし学習の一形態であるため、だから私はそれを紹介しません。</p><h4 id="机器学习具体流程-機械学習の具体的なプロセス"><a href="#机器学习具体流程-機械学習の具体的なプロセス" class="headerlink" title="机器学习具体流程 &#x2F; 機械学習の具体的なプロセス"></a>机器学习具体流程 &#x2F; 機械学習の具体的なプロセス</h4><p>机器学习首要的是数据，一般我们会把数据分为三个部分：训练集、验证集以及测试集。其中训练集占比最多大概在60%-80%，而验证集和测试集一般占比都在10%-20%。</p><p>&#x2F; 機械学習は何よりもまずデータであり、一般的にデータはトレーニングセット、検証セット、テストセットの3つの部分に分けられます。 その中で、トレーニングセットは最大で約60%〜80%を占め、検証セットとテストセットは通常10%〜20%を占めます。</p><p>作用如图所示 &#x2F; 効果を図に示します：<br><img src="/2023/09/13/2023-09-13%E5%91%A8%E6%8A%A5/01.png"></p><p>分好数据以后，我们可以根据需求选择合适的模型进行训练，例如我想让机器分出猫狗，那么就可以选择Logistic回归方法来解决。训练好以后的模型利用测试集对自身进行评估并且不断调整超参数，直至选出在测试集上效果最好的模型，然后利用验证集进行评估模型最终的学习效果。</p><p>&#x2F;データを分割した後、必要に応じてトレーニングに適したモデルを選択できます, たとえば、猫と犬を分離するためにマシンを使用する場合, ロジスティック回帰を選択して解決できます. トレーニング後、モデルは自己評価のためにテスト セットを使用し、テスト セットで最もパフォーマンスの高いモデルが選択されるまでハイパーパラメーターを継続的に調整し、検証セットを使用してモデルの最終的な学習効果を評価します。</p><p>如图所示 &#x2F; 効果を図に示します：<br><img src="/2023/09/13/2023-09-13%E5%91%A8%E6%8A%A5/02.png"></p><h4 id="如何建模？-モデル化するには"><a href="#如何建模？-モデル化するには" class="headerlink" title="如何建模？ &#x2F; モデル化するには?"></a>如何建模？ &#x2F; モデル化するには?</h4><p>训练模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为经验风险最小化。</p><p>&#x2F; トレーニング済みモデルは、ラベル付きサンプルを持つことにより、すべての重みとバイアスを学習 (決定) するための理想的な値を表します。 教師あり学習では、機械学習アルゴリズムは、複数のサンプルを調べ、損失を最小限に抑えるモデルを見つけようとすることによってモデルを構築します。 このプロセスは、経験的リスク最小化と呼ばれます。</p><h4 id="如何评估模型好坏？-モデルの品質を評価する方法は"><a href="#如何评估模型好坏？-モデルの品質を評価する方法は" class="headerlink" title="如何评估模型好坏？ &#x2F; モデルの品質を評価する方法は?"></a>如何评估模型好坏？ &#x2F; モデルの品質を評価する方法は?</h4><p>为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参数即为最优参数。</p><p>&#x2F; モデルがどの程度適合しているかを評価するために、通常、適合度は損失関数によって測定されます。 損失関数は最小化され、適合が最良であり、対応するモデルパラメータが最適なパラメータであることを意味します。</p><h5 id="损失函数（loss-function）-損失関数（loss-function）"><a href="#损失函数（loss-function）-損失関数（loss-function）" class="headerlink" title="损失函数（loss function） &#x2F; 損失関数（loss function）"></a>损失函数（loss function） &#x2F; 損失関数（loss function）</h5><p>损失函数就是用来度量模型的预测值f(x)与真实值Y的差异程度的运算函数。</p><p>&#x2F; 損失関数は、モデルの予測値f(x)と真の値Yとの差の度合いを測定する演算関数です。</p><h5 id="过拟合（Over-fitting）-オーバーフィッティング（Over-fitting）"><a href="#过拟合（Over-fitting）-オーバーフィッティング（Over-fitting）" class="headerlink" title="过拟合（Over fitting）&#x2F; オーバーフィッティング（Over fitting）"></a>过拟合（Over fitting）&#x2F; オーバーフィッティング（Over fitting）</h5><p>有时损失函数很小但最终的训练效果却并不好，因为模型太复杂，它过度学习历史数据，因此学习到的无关特征太多，这种情况称为过拟合。</p><p>&#x2F; 損失関数は小さいが、最終的なトレーニング効果は良くない、モデルが複雑すぎるため、履歴データを過剰に学習し、無関係な特徴を学習しすぎてオーバーフィットと呼ばれることがあります。</p><p>如图所示 &#x2F; 効果を図に示します：<br><img src="/2023/09/13/2023-09-13%E5%91%A8%E6%8A%A5/03.png"></p><blockquote><p>图源吴恩达机器学习 &#x2F; 出典:Andrew Ng 機械学習</p></blockquote><h5 id="正则化（Regularization）-本格化（Regularization）"><a href="#正则化（Regularization）-本格化（Regularization）" class="headerlink" title="正则化（Regularization） &#x2F; 本格化（Regularization）"></a>正则化（Regularization） &#x2F; 本格化（Regularization）</h5><p>为了防止机器学习中发生过拟合，需要在损失函数中加入正则项，这种情况称之为正则化。它对系数进行惩罚，通过向模型添加额外参数来防止模型过度拟合，这有助于提高模型的可靠性、速度和准确性。</p><p>&#x2F; 機械学習におけるオーバーフィッティングを防ぐためには、正則化と呼ばれる状況である損失関数に正則項を追加する必要があります。 係数にペナルティを課し、モデルにパラメーターを追加することでモデルのオーバーフィットを防ぎ、モデルの信頼性、速度、精度の向上に役立ちます。</p><p>关于机器学习的基础理论部分就到此为止啦，之后会慢慢更具体的算法内容。</p><p>&#x2F; これで機械学習に関する基本的な理論的部分は終わり、その後、より具体的なアルゴリズムの内容が徐々に続きます。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本周将学习基础的机器学习。&lt;/p&gt;
&lt;p&gt;&amp;#x2F; 今週は機械学習の基本を学びます。&lt;/p&gt;
&lt;h2 id=&quot;首先是机器学习-1つ目は機械学習です&quot;&gt;&lt;a href=&quot;#首先是机器学习-1つ目は機械学習です&quot; class=&quot;headerlink&quot; title=&quot;首先是机</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>2023.09.05周报 / 週報</title>
    <link href="http://likeyukiyuki.github.io/2023/09/05/2023-09-05%E5%91%A8%E6%8A%A5/"/>
    <id>http://likeyukiyuki.github.io/2023/09/05/2023-09-05%E5%91%A8%E6%8A%A5/</id>
    <published>2023-09-04T19:18:57.000Z</published>
    <updated>2023-09-13T13:06:59.606Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于图片不能显示的问题：已解决-画像が表示されない問題：解決済み"><a href="#关于图片不能显示的问题：已解决-画像が表示されない問題：解決済み" class="headerlink" title="关于图片不能显示的问题：已解决 &#x2F; 画像が表示されない問題：解決済み"></a>关于图片不能显示的问题：已解决 &#x2F; 画像が表示されない問題：解決済み</h2><p>之前尝试安装hexo-render-marked插件时正好遇上“package.json文件内没有md文件转html渲染器”的问题，于是耽搁了下来。当解决完上述问题时，再去安装插件就顺利很多了。<br>&#x2F; hexo-render-markedプラグインをインストールしようとしたところ、”package.jsonファイル内にmdファイルをhtmlに変換するレンダラーがない”という問題が発生しました、だから遅れが出た。上記の問題が解決されると、プラグインをインストールするのがとてもスムーズになった。<br>首先是键入命令:<br>&#x2F; 最初のステップは、コマンドを入力すること:</p><p><code>npm install hexo-renderer-marked --save</code></p><p>安装成功后，在_config.yml中修改配置：<br>&#x2F; インストールに成功したら、_config.ymlの設定を変更する：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">post_asset_folder: true //在创建一个新文章时自动创建同名文件夹，用于放图片  /   新しい投稿が作成されると自動的に同じ名前のフォルダが作成され、画像用に使用できます。</span><br><span class="line">marked:</span><br><span class="line">  prependRoot: true</span><br><span class="line">  postAsset: true</span><br></pre></td></tr></table></figure><p>然后在需要引用图片的博客内使用<code>![](图片路径)</code><br>&#x2F; 次に、画像を参照する必要があるブログ内で<code>![](图片路径)</code>を使用する<br>例如：我现在有一篇文章叫“番茄钟.md”，如图所示：<br>&#x2F; 例えば、写真のような “番茄钟.md “という記事がある：<br><img src="/2023/09/05/2023-09-05%E5%91%A8%E6%8A%A5/example_file.png"><br>我需要在这篇文章内引用一张图片，那我就把图片放同名文件夹“番茄钟”内,如图所示：<br>&#x2F; この記事では写真を引用する必要があるので、写真のように「番茄钟」という同名のフォルダに写真を入れておく：<br><img src="/2023/09/05/2023-09-05%E5%91%A8%E6%8A%A5/example_tomata.png"><br>接下来我只需要在“番茄钟.md”内写上相对路径即可，例如：<code>![](./番茄钟.md /zt.png)</code>,效果如图：<br>&#x2F; 次に「番茄钟.md」の内に相対パスを書くだけだ、例えば:<code>![](./番茄钟/zt.png)</code>、効果は写真の通り：<br><img src="/2023/09/05/2023-09-05%E5%91%A8%E6%8A%A5/example_use.png"><br>如果需要设置图片的尺寸可以使用标签：<code>&lt;img src=&quot;相对路径&quot; width=&quot;数值&quot; height=&quot;数值&quot;&gt;</code>。<br>&#x2F; 画像のサイズを設定する必要がある場合は、タグを使用することができます：<code>&lt;img src=&quot;相対パス&quot; width=&quot;数値&quot; height=&quot;数値&quot;&gt;</code>。<br>依旧用番茄钟举例子，如图所示：<br>&#x2F; まだトマトの時計を例にしている、下図に示すよう:<br><img src="/2023/09/05/2023-09-05%E5%91%A8%E6%8A%A5/example_size.png"><br>记得绝对路径一定要写对，当对放图片的文件夹重命名以后，一定要把路径内名字改成新的，不然点击文章以后，hexo网页会变成404。一开始我还很疑惑为什么主页运行正常但是一点击文章就404了呢，后来发现是因为把放图片的文件夹改名后忘记在md文件内改过来了。<br>&#x2F; 絶対パスを正しく書くことを忘れないでください、写真が保存されているフォルダの名前を変更した後、必ずパス名を新しいものに変更してください。そうしないと、記事をクリックした後、ヘキソのページが404エラーになる。最初は、ホームページは問題なく動いているのに、記事をクリックすると404になってしまうので不思議に思っていたのですが、写真を入れたフォルダの名前を変更し、mdファイルで変更するのを忘れていたのが原因だとわかりました。<br><img src="/2023/09/05/2023-09-05%E5%91%A8%E6%8A%A5/cause404.png"><br>关于图片的问题到此就完美解决啦~<br>&#x2F; 写真の問題はこれで完璧に解決した。</p><h2 id="有关Linux学习中遇到的问题-Linux学習についての質問"><a href="#有关Linux学习中遇到的问题-Linux学習についての質問" class="headerlink" title="有关Linux学习中遇到的问题 &#x2F; Linux学習についての質問"></a>有关Linux学习中遇到的问题 &#x2F; Linux学習についての質問</h2><p>目前仅仅进行了简单的命令行学习，有关复制文件的cp命令稍微有点困惑：需要获取的源文件是否需要指定路径呢。后来搞清楚了cp的命令格式<br>&#x2F; これまで簡単なコマンドライン学習しかしてこなかったが、ファイルをコピーするためのcpコマンドに少し戸惑っている：取得したいソースファイルへのパスを指定する必要がありますか？そして、cpコマンドの書式を理解した。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp [源文件路径] [目标文件路径]</span><br></pre></td></tr></table></figure><p>例如我有一个文件&#x2F;home&#x2F;yuki&#x2F;file.txt，我想在&#x2F;home&#x2F;yuki&#x2F;copy目录下复制一个文件，则需要运行:<br>&#x2F; 例えば、&#x2F;home&#x2F;yuki&#x2F;file.txtというファイルがあり、そのコピーを&#x2F;home&#x2F;yuki&#x2F;copyディレクトリに作りたい、そして、次のように実行する：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /home/yuki/file.txt /home/yuki/copy/file.txt</span><br></pre></td></tr></table></figure><p>示例用的都是绝对路径，当然也可换成相对路径。<br>&#x2F; 例では絶対パスを使用しているが、もちろん相対パスに置き換えることもできる。</p><h2 id="一些学习Linux的感悟-Linuxを学ぶためのいくつかの見識"><a href="#一些学习Linux的感悟-Linuxを学ぶためのいくつかの見識" class="headerlink" title="一些学习Linux的感悟 &#x2F; Linuxを学ぶためのいくつかの見識"></a>一些学习Linux的感悟 &#x2F; Linuxを学ぶためのいくつかの見識</h2><p>个人感受是Linux跟Windows最大的区别在于Linux基本上都是命令行，而Windows基本上都是可视化的工具，很早以前我刚刚学习编程连电脑都摸不清楚的时候对于命令行工具十分抗拒。一方面是完全不熟悉，甚至没有见过，于是对于陌生的东西自然而然感到恐惧。另外一方面是由于根本不理解命令行的意义，而且对于不能用肉眼看到变化的命令总是不相信的。<br>&#x2F; 私の個人的な感覚では、LinuxとWindowsの最大の違いは、Linuxが基本的にコマンドラインであるのに対し、Windowsは基本的にビジュアルツールであることだ。昔、プログラミングを習いたての頃、コンピューターもろくに使えなかった私は、コマンドラインツールにとても抵抗があった。一方では、まったく馴染みがない、あるいは見たことがないために、馴染みのないものに対する自然な恐怖がある。一方では、コマンドラインの意味を全然理解しておらず、そして、肉眼で変化を見えないコマンドはいつも信じらない。</p><p>在随着编程学习的不断深入，使用命令行工具也成了不可或缺的事情，由于之前在Windows中使用powershell也稍微有些经验后，再去接触Linux觉得对计算机操作系统的理解更深刻了。<br>&#x2F; プログラミング学習の深化に伴い、コマンドラインツールの使用は不可欠なものとなっているため、Windowsでもpowershellの使用前に若干の経験がある、その後、Linuxは、コンピュータのオペレーティングシステムのより深遠な理解を感じに触れに行く。</p><p>让我觉得比较有意思的指令是管道”|”和输出重定向”&gt;”,以前我从不知道在终端输入一个命令之后之后发生了什么事，系统又是做了什么从把我们想要的结果呈现在终端的。当我了解到管道”|”以后，我才知道一个程序的输出流可以接在另外一个程序的输入流上，所以可以同时组合不同的命令。了解”&gt;”后知道，我们可以重定向输出到某个文件（一般默认是输出到终端）。<br>&#x2F; 私が面白いと思ったコマンドは、パイプ「｜」と出力リダイレクト「&gt;」で、ターミナルにコマンドを入力した後に何が起こるのか、そしてターミナルに望む結果を得るためにシステムが何をするのか、私は知らなかった。 パイプ「｜」について学んだとき、あるプログラムの出力ストリームを別のプログラムの入力ストリームに接続することで、異なるコマンドを同時に組み合わせることができることを知った。 について学んだとき、出力をファイルにリダイレクトできることを学んだ（通常、デフォルトの出力はターミナルにある）。</p><p>例如我想创建一个文件并且把当前目录下所有的目录和文件名放入该文件，如果用图形界面操作就有点麻烦了，对我来说需要创建文件然后一个个复制粘贴进去，但是使用Linux只需要一个命令：<br>&#x2F; 例えば、あるファイルを作成し、そのファイルにカレント・ディレクトリー内のすべてのディレクトリーとファイル名を入れたい場合、グラフィカルインターフェイスでそれを行うのは少々面倒で、私はファイルを作成し、一つ一つコピー＆ペーストする必要があるが、Linuxでは一つのコマンドで済む：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls &gt; file</span><br></pre></td></tr></table></figure><p>如果我想查找字符串 “world”，并只打印匹配的行数：<br>\ 文字列 “world “を検索し、一致する行だけを表示したい場合：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;hello world&quot; | grep -c world</span><br></pre></td></tr></table></figure><p>最后一个觉得比较有意思的东西是vim，简单来说相当于Windows内的记事本，但是远比记事本方便快捷的的多。<br>\ 最後に私が面白いと思ったのはvimで、これは単にWindowsのメモ帳に相当するものだが、はるかに便利で速い。</p><p>我可以直接使用<code>vim file</code> 打开或者创建一个文件，也就是file存在则vim会为我打开它，要是不存在则会为我创建它。<br>\ <code>vim file</code>でファイルを直接開いたり作成したりする、つまり、ファイルが存在すればvimがそれを開いてくれるし、存在しなければファイルを作成してくれる。</p><p>vim打开文件后是命令行模式，在该模式下只能使用命令例如d删除光标所在的行，点击i进入输入模式，可以随意的输入内容。最后输入：进入末行模式中，输入wq可以保存并推出。<br>\ ファイルを開いた後のvimはコマンドラインモードで、このモードでは、カーソルがある行を削除するには、dなどのコマンドを使用することができ、入力モードに入るには、iをクリックして、自由に内容を入力することができます。 最後の入力：最後の行モードに入り、保存して起動するためにwqを入力します。</p><p>关于各个模式切换：默认就是命令行模式，按i、a或o进入编辑模式，再按ESC返回到命令行模式。在命令行模式输入冒号切换到末行模式，再按ESC又返回到命令行模式。编辑模式和末行模式之间不能直接切换，只能通过命令行模式切换。<br>\ 各モードの切り替えについて：デフォルトはコマンドラインモードで、i、a、または o を押して編集モードに入り、ESC を押してコマンドラインモードに戻ります。 コマンドラインモードでは、コロンを入力するとラストラインモードに切り替わり、ESCを押すとコマンドラインモードに戻ります。 編集モードと最終行モードを直接切り替えることはできません。</p><p>vim还有其他各种各样有用的功能，它可以将一个或多个命令写入文件，那只要运行该文件就可以得到一个高效的脚本了。不过具体的我还需要再慢慢探究，目前了解的信息大多是基于理论，后面会尽量通过实操提高理解的。<br>\ vimには他にもいろいろと便利な機能があって、1つ以上のコマンドをファイルに書き込んで、そのファイルを実行するだけで効率的なスクリプトを作ることができる。 でも、具体的なことはもっとゆっくり探っていく必要がある。今のところ知っている情報のほとんどは理論に基づいたもので、後で実際に手を動かして理解を深めていこうと思う。</p><p>这次的周报就到此为止啦。<br>\ 今回の週報は以上である。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;关于图片不能显示的问题：已解决-画像が表示されない問題：解決済み&quot;&gt;&lt;a href=&quot;#关于图片不能显示的问题：已解决-画像が表示されない問題：解決済み&quot; class=&quot;headerlink&quot; title=&quot;关于图片不能显示的问题：已解决 &amp;#x2F; 画像が表示</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>使用vue+python制作简易番茄钟/vue+pythonでシンプルなトマトクロックを作る</title>
    <link href="http://likeyukiyuki.github.io/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/"/>
    <id>http://likeyukiyuki.github.io/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/</id>
    <published>2023-09-04T19:11:51.065Z</published>
    <updated>2023-09-13T14:33:48.231Z</updated>
    
    <content type="html"><![CDATA[<h5 id="日期-デート-2023-09-01-02-51-26"><a href="#日期-デート-2023-09-01-02-51-26" class="headerlink" title="日期&#x2F;デート: 2023-09-01 02:51:26"></a>日期&#x2F;デート: 2023-09-01 02:51:26</h5><h3 id="网页整体如下-ページ全体は以下の通り："><a href="#网页整体如下-ページ全体は以下の通り：" class="headerlink" title="网页整体如下&#x2F;ページ全体は以下の通り："></a>网页整体如下&#x2F;ページ全体は以下の通り：</h3><p><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/zt.png"></p><h4 id="前端vue所实现的功能-フロントエンドのvueが実装する機能："><a href="#前端vue所实现的功能-フロントエンドのvueが実装する機能：" class="headerlink" title="前端vue所实现的功能&#x2F;フロントエンドのvueが実装する機能："></a>前端vue所实现的功能&#x2F;フロントエンドのvueが実装する機能：</h4><h4 id="1-实现计时器功能，即一轮30分钟的倒计时，前25分钟工作，后五分钟休息。-タイマー機能を導入する。つまり、30分のカウントダウンを繰り返し、最初の25分は仕事、最後の5分は休憩とする。"><a href="#1-实现计时器功能，即一轮30分钟的倒计时，前25分钟工作，后五分钟休息。-タイマー機能を導入する。つまり、30分のカウントダウンを繰り返し、最初の25分は仕事、最後の5分は休憩とする。" class="headerlink" title="1.实现计时器功能，即一轮30分钟的倒计时，前25分钟工作，后五分钟休息。&#x2F;タイマー機能を導入する。つまり、30分のカウントダウンを繰り返し、最初の25分は仕事、最後の5分は休憩とする。"></a>1.实现计时器功能，即一轮30分钟的倒计时，前25分钟工作，后五分钟休息。&#x2F;タイマー機能を導入する。つまり、30分のカウントダウンを繰り返し、最初の25分は仕事、最後の5分は休憩とする。</h4><blockquote><p>参考代码如下（写在script标签内的哦）&#x2F;参照コードは以下の通りである（scriptタグ内に記述）：</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义一些需要用到的变量/使用する変数を定義する</span></span><br><span class="line"><span class="keyword">const</span> seconds = <span class="title function_">ref</span>(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">const</span> minutes = <span class="title function_">ref</span>(<span class="number">30</span>);</span><br><span class="line"><span class="keyword">const</span> state = <span class="title function_">ref</span>(<span class="title class_">State</span>.<span class="property">Init</span>);</span><br><span class="line"><span class="keyword">const</span> is_pause = <span class="title function_">ref</span>(<span class="literal">false</span>);</span><br><span class="line"><span class="keyword">var</span> <span class="attr">timer</span>: <span class="built_in">number</span> | <span class="literal">undefined</span>;</span><br><span class="line"><span class="keyword">var</span> count=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">const</span> msg=<span class="title function_">ref</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义三种不同的状态/3つの異なる状態を定義する</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">State</span> &#123;</span><br><span class="line">  <span class="title class_">Init</span>, <span class="comment">// 初始/初期</span></span><br><span class="line">  <span class="title class_">Working</span>, <span class="comment">// 工作/仕事</span></span><br><span class="line">  <span class="title class_">Resting</span> <span class="comment">// 休息/休み</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//关于工作状态的设置/仕事の状況の設定について</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">message</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (state.<span class="property">value</span> === <span class="title class_">State</span>.<span class="property">Init</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;还未启动&quot;</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (state.<span class="property">value</span> === <span class="title class_">State</span>.<span class="property">Working</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;工作&quot;</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (state.<span class="property">value</span> === <span class="title class_">State</span>.<span class="property">Resting</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;休息&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//根据当前时间数值返回不同状态/現在の時間値に基づいて異なる状態を返す</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">clock</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (minutes.<span class="property">value</span> &gt; <span class="number">5</span> &amp;&amp; minutes.<span class="property">value</span> &lt; <span class="number">30</span>) &#123;</span><br><span class="line">    state.<span class="property">value</span> = <span class="title class_">State</span>.<span class="property">Working</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    state.<span class="property">value</span> = <span class="title class_">State</span>.<span class="property">Resting</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="预期实现效果如下图所示"><a href="#预期实现效果如下图所示" class="headerlink" title="预期实现效果如下图所示"></a>预期实现效果如下图所示</h6><p><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/clock——init.png" width="250" height="300"><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/clock——working.png" width="250" height="300"><br><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/clock——resting.png" width="250" height="300"><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/worked.png" width="250" height="300"></p><blockquote><p>这里设定了一个计时器，timefn()函数控制了计时的开始，pauseFn()函数控制了计时的结束&#x2F;ここではタイマーが設定され、timefn()関数がタイマーの開始を制御し、pauseFn()関数がタイマーの終了を制御する。</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">timeFn</span>(<span class="params"></span>) &#123;</span><br><span class="line">  is_pause.<span class="property">value</span> = <span class="literal">false</span>;</span><br><span class="line">  <span class="built_in">clearInterval</span>(timer);</span><br><span class="line">  timer = <span class="variable language_">window</span>.<span class="built_in">setInterval</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="title function_">clock</span>()</span><br><span class="line">    <span class="keyword">if</span> (minutes.<span class="property">value</span> &lt;= <span class="number">0</span> &amp;&amp; seconds.<span class="property">value</span> &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">      state.<span class="property">value</span> = <span class="title class_">State</span>.<span class="property">Init</span>;<span class="comment">//设置初始状态/初期状態の設定</span></span><br><span class="line">      count=<span class="number">1</span>;<span class="comment">//后期用的计算轮数的变量，可以先忽略/回数を計算するために後で使用する変数は、今は無視してもよい。</span></span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(count);</span><br><span class="line">      <span class="title function_">pauseFn</span>();</span><br><span class="line">      <span class="title function_">vue_count</span>();<span class="comment">//向后端传轮数的函数，可以先忽略/バックエンドに回数を渡す関数は、今のところ無視できる</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (seconds.<span class="property">value</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        seconds.<span class="property">value</span> = <span class="number">60</span>;</span><br><span class="line">        minutes.<span class="property">value</span>--;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        seconds.<span class="property">value</span>--;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;, <span class="number">1000</span>);</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//暂停倒计时/カウントダウンを停止する</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">pauseFn</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="built_in">clearInterval</span>(timer);</span><br><span class="line">  is_pause.<span class="property">value</span> = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>如果想要网页上提醒用户现在的状态，使用computed是非常方便的选择，参考代码如下&#x2F;ウェブページの現在の状態をユーザーに知らせるには、computedを使うのが便利です：</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> filled_minute = <span class="title function_">computed</span>(<span class="function">() =&gt;</span> <span class="title function_">fill</span>(minutes));</span><br><span class="line"><span class="keyword">const</span> filled_second = <span class="title function_">computed</span>(<span class="function">() =&gt;</span> <span class="title function_">fill</span>(seconds));</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> message_state = <span class="title function_">computed</span>(<span class="function">() =&gt;</span> <span class="title function_">message</span>());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">fill</span>(<span class="params">in_num: Ref&lt;<span class="built_in">number</span>&gt;</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (in_num.<span class="property">value</span> &gt;= <span class="number">10</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> in_num.<span class="property">value</span>.<span class="title function_">toString</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span> + in_num.<span class="property">value</span>.<span class="title function_">toString</span>();<span class="comment">//当倒计时到个位数时自动补零/カウントダウンが一桁になると、自動的にゼロを補充</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">unction <span class="title function_">click</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (minutes.<span class="property">value</span> &lt;= <span class="number">0</span> &amp;&amp; seconds.<span class="property">value</span> &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    </span><br><span class="line">    minutes.<span class="property">value</span> = <span class="number">30</span>;<span class="comment">//当倒计时结束重新启动时把时间补回30分钟/カウントダウンが終わって再開すると、時間は30分に戻される</span></span><br><span class="line">    seconds.<span class="property">value</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="title function_">timeFn</span>();</span><br><span class="line">    </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="title function_">timeFn</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>绑定到网页上的按钮（template标签内）&#x2F;ウェブページのボタンへのバインド（テンプレートタグ内）：</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;template&gt;</span><br><span class="line">            <span class="language-xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;width: 200px; height: 100px;clear: both;text-align: center;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">el-button</span> <span class="attr">style</span>=<span class="string">&quot;margin-top: 20%;margin-left: 65px;&quot;</span> <span class="attr">type</span>=<span class="string">&quot;primary&quot;</span> @<span class="attr">click</span>=<span class="string">&quot;click&quot;</span>&gt;</span>开始<span class="tag">&lt;/<span class="name">el-button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">el-button</span> <span class="attr">style</span>=<span class="string">&quot;margin-top: 20%;&quot;</span> <span class="attr">type</span>=<span class="string">&quot;danger&quot;</span> @<span class="attr">click</span>=<span class="string">&quot;pauseFn&quot;</span>&gt;</span>暂停<span class="tag">&lt;/<span class="name">el-button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">          <span class="language-xml"><span class="tag">&lt;<span class="name">el-footer</span>&gt;</span>现在是&#123;&#123; message_state &#125;&#125;时间哦~<span class="tag">&lt;/<span class="name">el-footer</span>&gt;</span></span></span><br><span class="line">&lt;/template&gt;</span><br><span class="line"> </span><br></pre></td></tr></table></figure><blockquote><p>接下来是一些附加的功能，主要是注册登录和获取排行榜信息。预期实现效果如下图&#x2F;次に、いくつかの追加機能、主に登録とログイン、そしてランキング情報の取得です。 予想される実装を以下に示します。<br>使用没有注册过的账号登录，页面提示账号不存在以后进行注册&#x2F;登録されていないアカウントでログインすると、アカウントは存在しませんと表示され、登録するよう促される。</p></blockquote><p><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/null.png"></p><p>注册成功以后登录&#x2F;登録が完了したらログインする：<br><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/login.png"><br>当密码错误时进行提示&#x2F;パスワードが間違っている場合の警告：<img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/login_fail.png"></p><h4 id="注册登录的参考代码如下-登録およびログインのための参照コードは以下の通りです"><a href="#注册登录的参考代码如下-登録およびログインのための参照コードは以下の通りです" class="headerlink" title="注册登录的参考代码如下&#x2F;登録およびログインのための参照コードは以下の通りです:"></a>注册登录的参考代码如下&#x2F;登録およびログインのための参照コードは以下の通りです:</h4><p>vue（script标签中）内代码&#x2F;vue内のコード（scriptタグ内）：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义请求成功后返回的string变量、リクエストが成功した場合に返される文字列変数を定義する</span></span><br><span class="line"><span class="keyword">const</span> aa = <span class="title function_">ref</span>(<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册/ログイン</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">register</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">let</span> res = <span class="keyword">await</span> axios.<span class="title function_">post</span>(<span class="string">&quot;http://localhost:8888/register&quot;</span>, <span class="comment">//使用axios向后端发送请求/axiosを使ったバックエンドへのリクエスト送信</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">user_id</span>: user.<span class="property">value</span>,</span><br><span class="line">    <span class="attr">password</span>: password.<span class="property">value</span>,<span class="comment">//发送了账号密码/アカウントのパスワードを送信</span></span><br><span class="line">    </span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="keyword">if</span> (res.<span class="property">status</span> == <span class="number">200</span>) &#123; <span class="comment">// 如果成功执行/正常に実行された場合</span></span><br><span class="line">    aa.<span class="property">value</span> = res.<span class="property">data</span><span class="comment">//返回值是一个字符串“注册成功”/戻り値は文字列 &quot;Registration Successful &quot;である。</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//登录/ログインする</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">login</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">let</span> res = <span class="keyword">await</span> axios.<span class="title function_">post</span>(<span class="string">&quot;http://localhost:8888/login&quot;</span>, &#123;</span><br><span class="line">    <span class="attr">user_id</span>: user.<span class="property">value</span>,</span><br><span class="line">    <span class="attr">password</span>: password.<span class="property">value</span>,</span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="keyword">if</span> (res.<span class="property">status</span> == <span class="number">200</span>) &#123; <span class="comment">// 如果成功执行/正常に実行された場合</span></span><br><span class="line">    aa.<span class="property">value</span> = res.<span class="property">data</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="title function_">vue_top</span>();<span class="comment">//后期获取排行榜使用的函数，可以先忽略/後の段階でランキングボードを取得するために使用される関数は、今のところ無視することができる。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>vue（template标签中）内&#x2F;vue（テンプレート・タグ内）:</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;div style=<span class="string">&quot;widows: 80px;height: 80px;clear: both;&quot;</span>&gt;</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">el-input</span> <span class="attr">v-model</span>=<span class="string">&quot;user&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请在此输入账号/用户名&quot;</span> /&gt;</span></span></span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">el-input</span> <span class="attr">v-model</span>=<span class="string">&quot;password&quot;</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请在此输入密码哦&quot;</span> <span class="attr">show-password</span> /&gt;</span></span></span><br><span class="line"></span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">el-button</span> <span class="attr">style</span>=<span class="string">&quot;margin-top: 20%;margin-left: 65px;&quot;</span> <span class="attr">type</span>=<span class="string">&quot;primary&quot;</span> @<span class="attr">click</span>=<span class="string">&quot;login&quot;</span>&gt;</span>登录<span class="tag">&lt;/<span class="name">el-button</span>&gt;</span></span></span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">el-button</span> <span class="attr">style</span>=<span class="string">&quot;margin-top: 20%;&quot;</span> <span class="attr">type</span>=<span class="string">&quot;success&quot;</span> @<span class="attr">click</span>=<span class="string">&quot;register&quot;</span>&gt;</span>注册<span class="tag">&lt;/<span class="name">el-button</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">el-text</span> <span class="attr">class</span>=<span class="string">&quot;mx-1&quot;</span> <span class="attr">type</span>=<span class="string">&quot;success&quot;</span>&gt;</span>&#123;&#123; aa &#125;&#125;<span class="tag">&lt;/<span class="name">el-text</span>&gt;</span></span></span><br><span class="line">      </span><br></pre></td></tr></table></figure><h4 id="后端python出场啦-バックエンドのpythonが出た"><a href="#后端python出场啦-バックエンドのpythonが出た" class="headerlink" title="后端python出场啦&#x2F;バックエンドのpythonが出た"></a>后端python出场啦&#x2F;バックエンドのpythonが出た</h4><blockquote><p>后端python中参考代码&#x2F;バックエンドの python の参照コード：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3 <span class="comment">#数据库用的sqlite3哦，记得自己在命令行里创建数据库/データベースはsqlite3です、コマンドラインでデータベースを作成することを忘れないでください。</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.middleware.cors <span class="keyword">import</span> CORSMiddleware <span class="comment"># 用来支持跨域/クロスドメインのサポートに使用される</span></span><br><span class="line"><span class="keyword">import</span> uvicorn <span class="comment"># 相当于服务器的启动器/サーバー起動装置に相当</span></span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel <span class="comment"># 用来定义POST请求接受的类型/受け入れられるPOSTリクエストのタイプを定義するために使用される。</span></span><br><span class="line"></span><br><span class="line">app = FastAPI() <span class="comment"># 定义后端服务器/バックエンドサーバーの定義</span></span><br><span class="line"><span class="comment"># 搜索关键词“跨域”，因为前端和后端不在同一个端口，所以为了安全，默认禁止互相访问，为了互相访问，我们需要跨域/クロス・ドメイン」というキーワードで検索すると、フロント・エンドとバック・エンドは同じポートに存在しないため、安全のためにデフォルトでは相互アクセスが禁止されており、相互アクセスするためにはクロス・ドメインする必要がある！</span></span><br><span class="line"><span class="comment"># 参考 https://blog.csdn.net/moshowgame/article/details/107285660</span></span><br><span class="line">app.add_middleware(</span><br><span class="line">CORSMiddleware,</span><br><span class="line"><span class="comment"># 允许跨域的源列表，例如 [&quot;http://www.example.org&quot;] 等等，[&quot;*&quot;] 表示允许任何源 / 許可されたクロスドメイン・ソースのリスト。例えば[&quot;http://www.example.org&quot;]など。[&quot;*&quot;]はどのソースでも許可されることを意味する。</span></span><br><span class="line">allow_origins=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line"><span class="comment"># 跨域请求是否支持 cookie，默认是 False，如果为 True，allow_origins 必须为具体的源，不可以是 [&quot;*&quot;] / クロスドメインリクエストがクッキーをサポートするかどうか。デフォルトは False。True の場合、allow_origins は [&quot;*&quot;] ではなく、ソースを指定しなければなりません。</span></span><br><span class="line">allow_credentials=<span class="literal">False</span>,</span><br><span class="line"><span class="comment"># 允许跨域请求的 HTTP 方法列表，默认是 [&quot;GET&quot;] / クロスドメインリクエストを許可するHTTPメソッドのリスト、デフォルトは[&quot;GET&quot;]。</span></span><br><span class="line">allow_methods=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line"><span class="comment"># 允许跨域请求的 HTTP 请求头列表，默认是 []，可以使用 [&quot;*&quot;] 表示允许所有的请求头 / クロスドメインリクエストで許可されるHTTPリクエストヘッダのリスト、デフォルトは[]、[&quot;*&quot;]を使用するとすべてのリクエストヘッダが許可されることを示す。</span></span><br><span class="line">allow_headers=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line"><span class="comment"># 可以被浏览器访问的响应头, 默认是 []，一般很少指定 / ブラウザがアクセスできるレスポンスヘッダ。デフォルトは[]で、指定されることはほとんどない。</span></span><br><span class="line"><span class="comment"># expose_headers=[&quot;*&quot;]</span></span><br><span class="line"><span class="comment"># 设定浏览器缓存 CORS 响应的最长时间，单位是秒。默认为 600，一般也很少指定 /ブラウザがCORS応答をキャッシュする最大時間を秒単位で設定する。 デフォルトは600で、指定されることはほとんどない。</span></span><br><span class="line"><span class="comment"># max_age=1000</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">#注释源自世界上最好的看我写不出来代码给我写了一份demo的好朋友，我自己写的注释离奇消失，直接把demo里的拿来用啦 /注釈はコードを書けなかった私にデモを書いてくれた世界最高の友人から,自分のコメントが妙に消えてしまったので、デモにあるものだけを使った。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义接收的对象 /受信オブジェクトの定義</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RegisterInfo</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    user_id: <span class="built_in">str</span></span><br><span class="line">    password: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/register&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">register</span>(<span class="params">info: RegisterInfo</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;/register: User(id:<span class="subst">&#123;info.user_id&#125;</span>) registered.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 连接数据库 /データベースへの接続</span></span><br><span class="line">    conn = sqlite3.connect(<span class="string">&#x27;test.db&#x27;</span>)</span><br><span class="line">    c = conn.cursor()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功连接数据库&quot;</span>)</span><br><span class="line">    <span class="comment"># 向表中添加账号密码 /テーブルへのアカウント・パスワードの追加</span></span><br><span class="line"></span><br><span class="line">    x: <span class="built_in">tuple</span>[<span class="built_in">int</span>] = c.execute(</span><br><span class="line">        <span class="string">&quot;select count(*) from user where id=?&quot;</span>, (info.user_id,)).fetchone()</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="comment"># 注册 /ログイン</span></span><br><span class="line">    n = x[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> n &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已有账号&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;已有账号，请登录哦&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        c.execute(<span class="string">&quot;INSERT INTO USER (id, password,count) VALUES (?, ?,0)&quot;</span>,</span><br><span class="line">                  (info.user_id, info.password))</span><br><span class="line">        conn.commit()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;数据插入成功&quot;</span>)</span><br><span class="line">        conn.close()</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;注册成功~&quot;</span></span><br><span class="line"><span class="comment"># 登录 / ログインする</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/login&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">login</span>(<span class="params">info: RegisterInfo</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;/login: User(id:<span class="subst">&#123;info.user_id&#125;</span>) registered.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 连接数据库 /データベースへの接続</span></span><br><span class="line">    conn = sqlite3.connect(<span class="string">&#x27;test.db&#x27;</span>)</span><br><span class="line">    c = conn.cursor()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功连接数据库&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证账号是否存在 /アカウントが存在することを確認する</span></span><br><span class="line">    uid: <span class="built_in">tuple</span>[<span class="built_in">int</span>] = c.execute(</span><br><span class="line">        <span class="string">&quot;select count(*) from user where id=?&quot;</span>, (info.user_id,)).fetchone()</span><br><span class="line">    ps = c.execute(<span class="string">&quot;select count(*) from user where password=?&quot;</span>,</span><br><span class="line">                   (info.password,)).fetchone()</span><br><span class="line">    cuid = uid[<span class="number">0</span>]</span><br><span class="line">    cps = ps[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> cuid &gt; <span class="number">0</span> <span class="keyword">and</span> cps &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (<span class="string">&quot;登录成功&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> cuid &gt; <span class="number">0</span> <span class="keyword">and</span> cps == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;cw&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> (<span class="string">&quot;密码错误&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> cuid == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;bcz&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> (<span class="string">&quot;账号不存在&quot;</span>)</span><br><span class="line">    conn.commit()</span><br><span class="line">    conn.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行fastapi程序，定式（记得放底部哦） /fastapiプログラムを実行し、数式を設定する（一番下に設定するのを忘れないように）。</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  uvicorn.run(app=<span class="string">&quot;main:app&quot;</span>, host=<span class="string">&quot;127.0.0.1&quot;</span>, port=<span class="number">8888</span>, reload=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="最后是排行榜功能，可以往前翻看计时器中的代码，轮数已经定义，所以接下来显示的参考代码需要结合计时器内代码一起使用哦"><a href="#最后是排行榜功能，可以往前翻看计时器中的代码，轮数已经定义，所以接下来显示的参考代码需要结合计时器内代码一起使用哦" class="headerlink" title="最后是排行榜功能，可以往前翻看计时器中的代码，轮数已经定义，所以接下来显示的参考代码需要结合计时器内代码一起使用哦~"></a>最后是排行榜功能，可以往前翻看计时器中的代码，轮数已经定义，所以接下来显示的参考代码需要结合计时器内代码一起使用哦~</h4><p><img src="/2023/09/05/%E7%95%AA%E8%8C%84%E9%92%9F/top.png"></p><blockquote><p>vue中（script）代码：</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//向后端传递番茄钟轮数 /トマトクロックの回数をバックエンドに渡す</span></span><br><span class="line"> <span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">vue_count</span>(<span class="params"></span>)&#123;</span><br><span class="line">      <span class="keyword">let</span> res =<span class="keyword">await</span> axios.<span class="title function_">post</span>(<span class="string">&quot;http://localhost:8888/count&quot;</span>, &#123;</span><br><span class="line">      <span class="attr">user_id</span>: user.<span class="property">value</span>,</span><br><span class="line">      <span class="attr">password</span>: password.<span class="property">value</span>,</span><br><span class="line">      <span class="attr">count</span>: count</span><br><span class="line">      &#125;)</span><br><span class="line">      <span class="keyword">if</span> (res.<span class="property">status</span> == <span class="number">200</span>) &#123; <span class="comment">// 如果成功执行 /正常に実行された場合</span></span><br><span class="line">        msg.<span class="property">value</span> = res.<span class="property">data</span></span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      &#125;</span><br><span class="line"><span class="comment">//获取排行榜内容 /ランキング・コンテンツを得る</span></span><br><span class="line"><span class="keyword">const</span> tableData=<span class="title function_">ref</span>([])</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">vue_top</span>(<span class="params"></span>)<span class="comment">//被放入登录函数内，在登录的同时拉取到排行榜 /ログイン関数に入れられ、ログインするとすぐにランキング・コンテンツをを得る</span></span><br><span class="line"> &#123;</span><br><span class="line">      <span class="keyword">let</span> res=<span class="keyword">await</span> axios.<span class="title function_">get</span>(<span class="string">&quot;http://localhost:8888/top&quot;</span>)</span><br><span class="line">      <span class="keyword">if</span>(res.<span class="property">status</span>==<span class="number">200</span>)&#123;</span><br><span class="line">        tableData.<span class="property">value</span>=res.<span class="property">data</span></span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>vue中（template）代码：</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;div style=<span class="string">&quot;color: lightpink; font-size: 30px; height: 800px; width: 200px;&quot;</span>&gt;</span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">el-aside</span> <span class="attr">width</span>=<span class="string">&quot;200px&quot;</span>&gt;</span>排行榜内容<span class="tag">&lt;/<span class="name">el-aside</span>&gt;</span></span></span><br><span class="line">        <span class="language-xml"><span class="tag">&lt;<span class="name">el-table</span> <span class="attr">:data</span>=<span class="string">&quot;tableData&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 200px&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">el-table-column</span> <span class="attr">prop</span>=<span class="string">&quot;id&quot;</span> <span class="attr">label</span>=<span class="string">&quot;id&quot;</span> <span class="attr">width</span>=<span class="string">&quot;80&quot;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">el-table-column</span> <span class="attr">prop</span>=<span class="string">&quot;count&quot;</span> <span class="attr">label</span>=<span class="string">&quot;count&quot;</span> <span class="attr">width</span>=<span class="string">&quot;80&quot;</span> /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">el-table</span>&gt;</span></span></span><br></pre></td></tr></table></figure><blockquote><p>python内代码</p></blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加轮数 /ラウンドを追加</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/count&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count</span>(<span class="params">info: countInfo</span>):</span><br><span class="line">    <span class="comment"># print(f&quot;/count: User(id:&#123;info.user_id&#125;) registered.&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 连接数据库 /データベースへの接続</span></span><br><span class="line">    conn = sqlite3.connect(<span class="string">&#x27;test.db&#x27;</span>)</span><br><span class="line">    c = conn.cursor()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功连接数据库&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># sql</span></span><br><span class="line">    n = c.execute(<span class="string">&quot;select count from user where id=?&quot;</span>,(info.user_id,)).fetchone()</span><br><span class="line">    n_count=n[<span class="number">0</span>]</span><br><span class="line">    c.execute(<span class="string">&quot;update user set count=?+? where id=?&quot;</span>, ( info.count,n_count,info.user_id))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功添加轮数&quot;</span>)</span><br><span class="line">    conn.commit()</span><br><span class="line">    conn.close()</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;成功完成一次~&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取排行榜内容 /ランキング・コンテンツを得る</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/top&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">top</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;/top:接收到信息&quot;</span>)</span><br><span class="line"></span><br><span class="line">     <span class="comment"># 连接数据库 /データベースへの接続</span></span><br><span class="line">    conn = sqlite3.connect(<span class="string">&#x27;test.db&#x27;</span>)</span><br><span class="line">    c = conn.cursor()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功连接数据库&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#按照count降序查询用户名和count /countの降順で、ユーザー名とcountのクエリーを実行する</span></span><br><span class="line">    tabledata=[]</span><br><span class="line">    </span><br><span class="line">    top_list= c.execute(<span class="string">&quot;select id,count from user order by count desc&quot;</span>).fetchall()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> top_list:</span><br><span class="line">        data_item=&#123;&#125;</span><br><span class="line">        data_item[<span class="string">&quot;id&quot;</span>]=data[<span class="number">0</span>]</span><br><span class="line">        data_item[<span class="string">&quot;count&quot;</span>]=data[<span class="number">1</span>]</span><br><span class="line">        tabledata.append(data_item)</span><br><span class="line">    <span class="built_in">print</span>(tabledata)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功获取排行榜&quot;</span>)</span><br><span class="line">    conn.commit()</span><br><span class="line">    conn.close()</span><br><span class="line">    <span class="keyword">return</span> tabledata</span><br></pre></td></tr></table></figure><blockquote><p>以上就是全部内容啦，感谢观看~&#x2F;以上です。ご視聴ありがとうございました！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h5 id=&quot;日期-デート-2023-09-01-02-51-26&quot;&gt;&lt;a href=&quot;#日期-デート-2023-09-01-02-51-26&quot; class=&quot;headerlink&quot; title=&quot;日期&amp;#x2F;デート: 2023-09-01 02:51:26&quot;&gt;&lt;/a&gt;日期</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>周报-2023.09.04</title>
    <link href="http://likeyukiyuki.github.io/2023/09/04/2023-09-04%E5%91%A8%E6%8A%A5/"/>
    <id>http://likeyukiyuki.github.io/2023/09/04/2023-09-04%E5%91%A8%E6%8A%A5/</id>
    <published>2023-09-04T12:52:09.000Z</published>
    <updated>2023-09-04T16:41:19.926Z</updated>
    
    <content type="html"><![CDATA[<p>这份周报记录的是上周的工作内容，由于一些原因今天才写成。</p><h1 id="上周的主要工作内容是"><a href="#上周的主要工作内容是" class="headerlink" title="上周的主要工作内容是"></a>上周的主要工作内容是</h1><ol><li>将番茄钟彻底完工收尾</li><li>搭建了个人博客</li><li>将番茄钟的相关内容写成文档上传到博客上</li></ol><h2 id="番茄钟收尾中遇到的问题"><a href="#番茄钟收尾中遇到的问题" class="headerlink" title="番茄钟收尾中遇到的问题"></a>番茄钟收尾中遇到的问题</h2><h4 id="调试方面"><a href="#调试方面" class="headerlink" title="调试方面"></a>调试方面</h4><p>在之前编写的过程中都没有进行过断点调试，后来尝试在后端进行断点调试的时候遇到了一些问题。<br>首先是在vscode中断点调试也是在需要进行断点的代码行旁进行断点添加，然后在运行调试即可。<br>而我始终开始运行调试后始终没有响应，后来发现是因为一开始已经启动了后端，而进行调试的时候又启动了一次后端，等于在调试时有两个后端，因此前端发送的请求并没有被当前调试的后端接受到，所以就一直没有反应。<br>其次是在调试后端时如果需要触发断点需要前端发送的请求，所以在前端也必须进行相应的操作对后端发送请求才行。</p><h4 id="代码部分-增加轮数"><a href="#代码部分-增加轮数" class="headerlink" title="代码部分-增加轮数"></a>代码部分-增加轮数</h4><p>一开始我的想法是定义一个变量count，当一轮计数结束时count++。但是一开始把它添加进了click函数（此函数由点击开始按钮触发）里。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">click</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (minutes.<span class="property">value</span> &lt;= <span class="number">0</span> &amp;&amp; seconds.<span class="property">value</span> &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    </span><br><span class="line">    minutes.<span class="property">value</span> = <span class="number">30</span>;</span><br><span class="line">    seconds.<span class="property">value</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="title function_">timeFn</span>();</span><br><span class="line">    <span class="comment">// msg.value=count.toString()</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="title function_">timeFn</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>造成的结果是我无论运行了几轮，count始终等于1。后来经过朋友的提醒我才想到count这种计数的变量应该加入计时器timefn函数中，而不是需要点击才会触发的click函数里，由此解决了问题。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">timeFn</span>(<span class="params"></span>) &#123;</span><br><span class="line">  is_pause.<span class="property">value</span> = <span class="literal">false</span>;</span><br><span class="line">  <span class="built_in">clearInterval</span>(timer);</span><br><span class="line">  timer = <span class="variable language_">window</span>.<span class="built_in">setInterval</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="title function_">clock</span>()</span><br><span class="line">    <span class="keyword">if</span> (minutes.<span class="property">value</span> &lt;= <span class="number">0</span> &amp;&amp; seconds.<span class="property">value</span> &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">      state.<span class="property">value</span> = <span class="title class_">State</span>.<span class="property">Init</span>;</span><br><span class="line">      count=<span class="number">1</span>;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(count);</span><br><span class="line">      <span class="title function_">pauseFn</span>();</span><br><span class="line">      <span class="title function_">vue_count</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (seconds.<span class="property">value</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        seconds.<span class="property">value</span> = <span class="number">60</span>;</span><br><span class="line">        minutes.<span class="property">value</span>--;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        seconds.<span class="property">value</span>--;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;, <span class="number">1000</span>);</span><br></pre></td></tr></table></figure><p>  番茄钟里的问题就到此为止啦。</p><h2 id="搭建个人博客时遇到的问题"><a href="#搭建个人博客时遇到的问题" class="headerlink" title="搭建个人博客时遇到的问题"></a>搭建个人博客时遇到的问题</h2><p>我采用的是hexo加git，一开始参照教程一路走下来挺顺畅的（其实也不是，但是主要问题都是由于没有认真看教程的锅，下次一定要认真看教程），但是当配置主题出现问题的时候想要利用git恢复版本却发现了问题。</p><h4 id="源代码并没有被git管理"><a href="#源代码并没有被git管理" class="headerlink" title="源代码并没有被git管理"></a>源代码并没有被git管理</h4><p>当我遇到问题想要恢复版本时发现，git管理的是hexo生成的网页文件，源代码并没有被git管理，而网页文件恰恰是依靠源代码进行生成的，于是我在尝试过多种方法解决无果之后重新搭建了一次，在搭建成功后立刻在git上创建分支将源代码提交到新分支进行管理。</p><h2 id="将写好的文档放入博客时遇到的问题"><a href="#将写好的文档放入博客时遇到的问题" class="headerlink" title="将写好的文档放入博客时遇到的问题"></a>将写好的文档放入博客时遇到的问题</h2><p>其实第一篇番茄钟放入博客时非常顺利，唯一的问题是图片不能正常显示。但是在后面我想使用插件让图片可以正常显示时发生了问题，下载完插件后进行本地运行，博客主页显示”cannot get&#x2F;“ 在网上查询解决方案后开始排查问题。</p><ol><li>source&#x2F;posts里没有放md文件<br>不成立，一开始就放入写了番茄钟的md文件了</li><li>public里的index.html文件为0kb<br>我去检查了public文件内的index.html文件，发现根本不存在。</li><li>public里没有index.html文件<br>看来就是这个原因了<br>然后这时朋友帮忙远程解决了问题，网页正常显示了。虽然图片的问题还没解决，但我想先暂时把周报写完再继续搞图片的问题，就在我生成新文章时，网页出现“cannot get&#x2F;”的事情又发生了。<br>最后弄了半天终于解决，以下是朋友帮忙解决后总结的思路：</li><li>我们只做了少量的修改却导致严重问题 -&gt; 问题出在git版本管理之外的文件</li><li>我们仔细检查了hexo的配置 -&gt; 不太可能是hexo配置或文件出错</li><li>public内任何html文件没有正确生成 -&gt; 可能是markdown转html的步骤出错<br>再进一步思考</li><li>1-&gt; git管理之外的文件，deploy、public这些是动态生成的，肯定不会是他们的问题，node_modules是根据package.json生成的，如果有问题，说明两个都有问题</li><li>2-&gt; 说明hexo确实没问题</li><li>3-&gt; 说明可能是md转html的渲染器问题<br>因此，可以得出结论，是之前自己操作时(或者hexo在默认情况下)，没有把必要的md转html渲染器放到 package.json 中，也就是 npm install 时没有加 –save参数，导致这个插件存在于 node_modules 文件夹内（因为我们最开始能运行），但是在进行了npm操作后，由于这个插件不在 package.json 中，被npm卸载了。</li><li>“npm install 名称”只是下载这个插件</li><li>“npm install –save 名称”是下载这个插件并且存入package.json</li><li>而”npm install”是把本地的 node_modules 按照 package.json 进行修改<br>因此，没有save的情况下下载后，再进行npm操作，就可能会把下载的插件卸载掉。在重新下载了必要插件，并且用save保存到了package.json中以后这个问题就圆满解决啦。</li></ol><h2 id="本周的计划"><a href="#本周的计划" class="headerlink" title="本周的计划"></a>本周的计划</h2><h4 id="1-学习Linux操作系统"><a href="#1-学习Linux操作系统" class="headerlink" title="1.学习Linux操作系统"></a>1.学习Linux操作系统</h4><p>初步了解并且学会使用相关命令。</p><h4 id="2-解决博客不显示图片的问题"><a href="#2-解决博客不显示图片的问题" class="headerlink" title="2.解决博客不显示图片的问题"></a>2.解决博客不显示图片的问题</h4><p>这个问题也算是存在许久了，本周一定要解决掉</p><hr><p>目前想法就这些了，希望这周的计划可以顺利进行。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这份周报记录的是上周的工作内容，由于一些原因今天才写成。&lt;/p&gt;
&lt;h1 id=&quot;上周的主要工作内容是&quot;&gt;&lt;a href=&quot;#上周的主要工作内容是&quot; class=&quot;headerlink&quot; title=&quot;上周的主要工作内容是&quot;&gt;&lt;/a&gt;上周的主要工作内容是&lt;/h1&gt;&lt;ol&gt;
</summary>
      
    
    
    
    
  </entry>
  
</feed>
